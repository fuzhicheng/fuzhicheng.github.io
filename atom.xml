<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>FF</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-09-14T07:21:50.364Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>FF</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis配置文件</title>
    <link href="http://yoursite.com/2017/09/14/Redis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"/>
    <id>http://yoursite.com/2017/09/14/Redis配置文件/</id>
    <published>2017-09-14T07:21:00.000Z</published>
    <updated>2017-09-14T07:21:50.364Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div><div class="line">443</div><div class="line">444</div><div class="line">445</div><div class="line">446</div><div class="line">447</div><div class="line">448</div><div class="line">449</div><div class="line">450</div><div class="line">451</div><div class="line">452</div><div class="line">453</div><div class="line">454</div><div class="line">455</div><div class="line">456</div><div class="line">457</div><div class="line">458</div><div class="line">459</div><div class="line">460</div><div class="line">461</div><div class="line">462</div><div class="line">463</div><div class="line">464</div><div class="line">465</div><div class="line">466</div><div class="line">467</div><div class="line">468</div><div class="line">469</div><div class="line">470</div><div class="line">471</div><div class="line">472</div><div class="line">473</div><div class="line">474</div><div class="line">475</div><div class="line">476</div><div class="line">477</div><div class="line">478</div><div class="line">479</div><div class="line">480</div><div class="line">481</div><div class="line">482</div><div class="line">483</div><div class="line">484</div><div class="line">485</div><div class="line">486</div><div class="line">487</div><div class="line">488</div><div class="line">489</div><div class="line">490</div><div class="line">491</div><div class="line">492</div><div class="line">493</div><div class="line">494</div><div class="line">495</div><div class="line">496</div><div class="line">497</div><div class="line">498</div><div class="line">499</div><div class="line">500</div><div class="line">501</div><div class="line">502</div><div class="line">503</div><div class="line">504</div><div class="line">505</div><div class="line">506</div><div class="line">507</div><div class="line">508</div><div class="line">509</div><div class="line">510</div><div class="line">511</div><div class="line">512</div><div class="line">513</div><div class="line">514</div><div class="line">515</div><div class="line">516</div><div class="line">517</div><div class="line">518</div><div class="line">519</div><div class="line">520</div><div class="line">521</div><div class="line">522</div><div class="line">523</div><div class="line">524</div><div class="line">525</div><div class="line">526</div><div class="line">527</div><div class="line">528</div><div class="line">529</div><div class="line">530</div><div class="line">531</div><div class="line">532</div><div class="line">533</div><div class="line">534</div><div class="line">535</div><div class="line">536</div><div class="line">537</div><div class="line">538</div><div class="line">539</div><div class="line">540</div><div class="line">541</div><div class="line">542</div><div class="line">543</div><div class="line">544</div><div class="line">545</div><div class="line">546</div><div class="line">547</div><div class="line">548</div><div class="line">549</div><div class="line">550</div><div class="line">551</div><div class="line">552</div><div class="line">553</div><div class="line">554</div><div class="line">555</div><div class="line">556</div><div class="line">557</div><div class="line">558</div><div class="line">559</div><div class="line">560</div><div class="line">561</div><div class="line">562</div><div class="line">563</div><div class="line">564</div><div class="line">565</div><div class="line">566</div><div class="line">567</div><div class="line">568</div><div class="line">569</div><div class="line">570</div><div class="line">571</div></pre></td><td class="code"><pre><div class="line"># Redis 配置文件示例</div><div class="line"></div><div class="line"># 注意单位: 当需要配置内存大小时, 可能需要指定像1k,5GB,4M等常见格式</div><div class="line">#</div><div class="line"># 1k =&gt; 1000 bytes</div><div class="line"># 1kb =&gt; 1024 bytes</div><div class="line"># 1m =&gt; 1000000 bytes</div><div class="line"># 1mb =&gt; 1024*1024 bytes</div><div class="line"># 1g =&gt; 1000000000 bytes</div><div class="line"># 1gb =&gt; 1024*1024*1024 bytes</div><div class="line">#</div><div class="line"># 单位是对大小写不敏感的 1GB 1Gb 1gB 是相同的。</div><div class="line"></div><div class="line">################################## INCLUDES ###################################</div><div class="line"></div><div class="line"># 可以在这里包含一个或多个其他的配置文件。如果你有一个适用于所有Redis服务器的标准配置模板</div><div class="line"># 但也需要一些每个服务器自定义的设置，这个功能将很有用。被包含的配置文件也可以包含其他配置文件，</div><div class="line"># 所以需要谨慎的使用这个功能。</div><div class="line">#</div><div class="line"># 注意“inclue”选项不能被admin或Redis哨兵的&quot;CONFIG REWRITE&quot;命令重写。</div><div class="line"># 因为Redis总是使用最后解析的配置行最为配置指令的值, 你最好在这个文件的开头配置includes来</div><div class="line"># 避免它在运行时重写配置。</div><div class="line"># 如果相反你想用includes的配置覆盖原来的配置，你最好在该文件的最后使用include</div><div class="line">#</div><div class="line"># include /path/to/local.conf</div><div class="line"># include /path/to/other.conf</div><div class="line"></div><div class="line">################################ GENERAL  #####################################</div><div class="line"></div><div class="line"># 默认Rdis不会作为守护进程运行。如果需要的话配置成&apos;yes&apos;</div><div class="line"># 注意配置成守护进程后Redis会将进程号写入文件/var/run/redis.pid</div><div class="line">daemonize no</div><div class="line"></div><div class="line"># 当以守护进程方式运行时，默认Redis会把进程ID写到 /var/run/redis.pid。你可以在这里修改路径。</div><div class="line">pidfile /var/run/redis.pid</div><div class="line"></div><div class="line"># 接受连接的特定端口，默认是6379</div><div class="line"># 如果端口设置为0，Redis就不会监听TCP套接字。</div><div class="line">port 6379</div><div class="line"></div><div class="line"># TCP listen() backlog.</div><div class="line">#</div><div class="line"># 在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意Linux内核默默地将这个值减小</div><div class="line"># 到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog</div><div class="line"># 两个值来达到想要的效果。</div><div class="line">tcp-backlog 511</div><div class="line"></div><div class="line"># 默认Redis监听服务器上所有可用网络接口的连接。可以用&quot;bind&quot;配置指令跟一个或多个ip地址来实现</div><div class="line"># 监听一个或多个网络接口</div><div class="line">#</div><div class="line"># 示例:</div><div class="line">#</div><div class="line"># bind 192.168.1.100 10.0.0.1</div><div class="line"># bind 127.0.0.1</div><div class="line"></div><div class="line"># 指定用来监听Unix套套接字的路径。没有默认值， 所以在没有指定的情况下Redis不会监听Unix套接字</div><div class="line">#</div><div class="line"># unixsocket /tmp/redis.sock</div><div class="line"># unixsocketperm 755</div><div class="line"></div><div class="line"># 一个客户端空闲多少秒后关闭连接。(0代表禁用，永不关闭)</div><div class="line">timeout 0</div><div class="line"></div><div class="line"># TCP keepalive.</div><div class="line">#</div><div class="line"># 如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACK，由于以下两个原因这是很有用的：</div><div class="line">#</div><div class="line"># 1）能够检测无响应的对端</div><div class="line"># 2）让该连接中间的网络设备知道这个连接还存活</div><div class="line">#</div><div class="line"># 在Linux上，这个指定的值(单位：秒)就是发送ACK的时间间隔。</div><div class="line"># 注意：要关闭这个连接需要两倍的这个时间值。</div><div class="line"># 在其他内核上这个时间间隔由内核配置决定</div><div class="line">#</div><div class="line"># 这个选项的一个合理值是60秒</div><div class="line">tcp-keepalive 0</div><div class="line"></div><div class="line"># 指定服务器调试等级</div><div class="line"># 可能值：</div><div class="line"># debug （大量信息，对开发/测试有用）</div><div class="line"># verbose （很多精简的有用信息，但是不像debug等级那么多）</div><div class="line"># notice （适量的信息，基本上是你生产环境中需要的）</div><div class="line"># warning （只有很重要/严重的信息会记录下来）</div><div class="line">loglevel notice</div><div class="line"></div><div class="line"># 指明日志文件名。也可以使用&quot;stdout&quot;来强制让Redis把日志信息写到标准输出上。</div><div class="line"># 注意:如果Redis以守护进程方式运行，而设置日志显示到标准输出的话，日志会发送到/dev/null</div><div class="line">logfile &quot;&quot;</div><div class="line"></div><div class="line"># 要使用系统日志记录器，只要设置 &quot;syslog-enabled&quot; 为 &quot;yes&quot; 就可以了。</div><div class="line"># 然后根据需要设置其他一些syslog参数就可以了。</div><div class="line"># syslog-enabled no</div><div class="line"></div><div class="line"># 指明syslog身份</div><div class="line"># syslog-ident redis</div><div class="line"></div><div class="line"># 指明syslog的设备。必须是user或LOCAL0 ~ LOCAL7之一。</div><div class="line"># syslog-facility local0</div><div class="line"></div><div class="line"># 设置数据库个数。默认数据库是 DB 0，</div><div class="line"># 可以通过select &lt;dbid&gt;  (0 &lt;= dbid &lt;= &apos;databases&apos; - 1 ）来为每个连接使用不同的数据库。</div><div class="line">databases 16</div><div class="line"></div><div class="line">################################ SNAPSHOTTING  ################################</div><div class="line">#</div><div class="line"># 把数据库存到磁盘上:</div><div class="line">#</div><div class="line">#   save &lt;seconds&gt; &lt;changes&gt;</div><div class="line">#   </div><div class="line">#   会在指定秒数和数据变化次数之后把数据库写到磁盘上。</div><div class="line">#</div><div class="line">#   下面的例子将会进行把数据写入磁盘的操作:</div><div class="line">#   900秒（15分钟）之后，且至少1次变更</div><div class="line">#   300秒（5分钟）之后，且至少10次变更</div><div class="line">#   60秒之后，且至少10000次变更</div><div class="line">#</div><div class="line">#   注意：你要想不写磁盘的话就把所有 &quot;save&quot; 设置注释掉就行了。</div><div class="line">#</div><div class="line">#   通过添加一条带空字符串参数的save指令也能移除之前所有配置的save指令</div><div class="line">#   像下面的例子：</div><div class="line">#   save &quot;&quot; </div><div class="line"></div><div class="line">save 900 1</div><div class="line">save 300 10</div><div class="line">save 60 10000</div><div class="line"></div><div class="line"># 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作</div><div class="line"># 这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难。</div><div class="line">#</div><div class="line"># 如果后台保存进程能重新开始工作，Redis将自动允许写操作</div><div class="line">#</div><div class="line"># 然而如果你已经部署了适当的Redis服务器和持久化的监控，你可能想关掉这个功能以便于即使是</div><div class="line"># 硬盘，权限等出问题了Redis也能够像平时一样正常工作，</div><div class="line">stop-writes-on-bgsave-error yes</div><div class="line"></div><div class="line"># 当导出到 .rdb 数据库时是否用LZF压缩字符串对象？</div><div class="line"># 默认设置为 &quot;yes&quot;，因为几乎在任何情况下它都是不错的。</div><div class="line"># 如果你想节省CPU的话你可以把这个设置为 &quot;no&quot;，但是如果你有可压缩的key和value的话，</div><div class="line"># 那数据文件就会更大了。</div><div class="line">rdbcompression yes</div><div class="line"></div><div class="line"># 因为版本5的RDB有一个CRC64算法的校验和放在了文件的最后。这将使文件格式更加可靠但在</div><div class="line"># 生产和加载RDB文件时，这有一个性能消耗(大约10%)，所以你可以关掉它来获取最好的性能。</div><div class="line">#</div><div class="line"># 生成的关闭校验的RDB文件有一个0的校验和，它将告诉加载代码跳过检查</div><div class="line">rdbchecksum yes</div><div class="line"></div><div class="line"># 持久化数据库的文件名</div><div class="line">dbfilename dump.rdb</div><div class="line"></div><div class="line"># 工作目录</div><div class="line">#</div><div class="line"># 数据库会写到这个目录下，文件名就是上面的 &quot;dbfilename&quot; 的值。</div><div class="line"># </div><div class="line"># 累加文件也放这里。</div><div class="line"># </div><div class="line"># 注意你这里指定的必须是目录，不是文件名。</div><div class="line">dir ./</div><div class="line"></div><div class="line">################################# REPLICATION #################################</div><div class="line"># 主从同步。通过 slaveof 指令来实现Redis实例的备份。</div><div class="line"># 注意，这里是本地从远端复制数据。也就是说，本地可以有不同的数据库文件、绑定不同的IP、监听</div><div class="line"># 不同的端口。</div><div class="line">#</div><div class="line"># slaveof &lt;masterip&gt; &lt;masterport&gt;</div><div class="line"></div><div class="line"># 如果master设置了密码保护（通过 &quot;requirepass&quot; 选项来配置），那么slave在开始同步之前必须</div><div class="line"># 进行身份验证，否则它的同步请求会被拒绝。</div><div class="line">#</div><div class="line"># masterauth &lt;master-password&gt;</div><div class="line"></div><div class="line"># 当一个slave失去和master的连接，或者同步正在进行中，slave的行为有两种可能：</div><div class="line">#</div><div class="line"># 1) 如果 slave-serve-stale-data 设置为 &quot;yes&quot; (默认值)，slave会继续响应客户端请求，</div><div class="line">#    可能是正常数据，也可能是还没获得值的空数据。</div><div class="line"># 2) 如果 slave-serve-stale-data 设置为 &quot;no&quot;，slave会回复&quot;正在从master同步</div><div class="line">#   （SYNC with master in progress）&quot;来处理各种请求，除了 INFO 和 SLAVEOF 命令。</div><div class="line">#</div><div class="line">slave-serve-stale-data yes</div><div class="line"></div><div class="line"># 你可以配置salve实例是否接受写操作。可写的slave实例可能对存储临时数据比较有用(因为写入salve</div><div class="line"># 的数据在同master同步之后将很容被删除)，但是如果客户端由于配置错误在写入时也可能产生一些问题。</div><div class="line">#</div><div class="line"># 从Redis2.6默认所有的slave为只读</div><div class="line">#</div><div class="line"># 注意:只读的slave不是为了暴露给互联网上不可信的客户端而设计的。它只是一个防止实例误用的保护层。</div><div class="line"># 一个只读的slave支持所有的管理命令比如config,debug等。为了限制你可以用&apos;rename-command&apos;来</div><div class="line"># 隐藏所有的管理和危险命令来增强只读slave的安全性</div><div class="line">slave-read-only yes</div><div class="line"></div><div class="line"># slave根据指定的时间间隔向master发送ping请求。</div><div class="line"># 时间间隔可以通过 repl_ping_slave_period 来设置。</div><div class="line"># 默认10秒。</div><div class="line">#</div><div class="line"># repl-ping-slave-period 10</div><div class="line"></div><div class="line"># 以下选项设置同步的超时时间</div><div class="line">#</div><div class="line"># 1）slave在与master SYNC期间有大量数据传输，造成超时</div><div class="line"># 2）在slave角度，master超时，包括数据、ping等</div><div class="line"># 3）在master角度，slave超时，当master发送REPLCONF ACK pings</div><div class="line"># </div><div class="line"># 确保这个值大于指定的repl-ping-slave-period，否则在主从间流量不高时每次都会检测到超时</div><div class="line">#</div><div class="line"># repl-timeout 60</div><div class="line"></div><div class="line"># 是否在slave套接字发送SYNC之后禁用 TCP_NODELAY ？</div><div class="line">#</div><div class="line"># 如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave</div><div class="line"># 上有延迟，Linux内核的默认配置会达到40毫秒</div><div class="line">#</div><div class="line"># 如果你选择了 &quot;no&quot; 数据传输到salve的延迟将会减少但要使用更多的带宽</div><div class="line">#</div><div class="line"># 默认我们会为低延迟做优化，但高流量情况或主从之间的跳数过多时，把这个选项设置为“yes”</div><div class="line"># 是个不错的选择。</div><div class="line">repl-disable-tcp-nodelay no</div><div class="line"></div><div class="line"># 设置数据备份的backlog大小。backlog是一个slave在一段时间内断开连接时记录salve数据的缓冲，</div><div class="line"># 所以一个slave在重新连接时，不必要全量的同步，而是一个增量同步就足够了，将在断开连接的这段</div><div class="line"># 时间内slave丢失的部分数据传送给它。</div><div class="line">#</div><div class="line"># 同步的backlog越大，slave能够进行增量同步并且允许断开连接的时间就越长。</div><div class="line">#</div><div class="line"># backlog只分配一次并且至少需要一个slave连接</div><div class="line">#</div><div class="line"># repl-backlog-size 1mb</div><div class="line"></div><div class="line"># 当master在一段时间内不再与任何slave连接，backlog将会释放。以下选项配置了从最后一个</div><div class="line"># slave断开开始计时多少秒后，backlog缓冲将会释放。</div><div class="line">#</div><div class="line"># 0表示永不释放backlog</div><div class="line">#</div><div class="line"># repl-backlog-ttl 3600</div><div class="line"></div><div class="line"># slave的优先级是一个整数展示在Redis的Info输出中。如果master不再正常工作了，哨兵将用它来</div><div class="line"># 选择一个slave提升=升为master。</div><div class="line">#</div><div class="line"># 优先级数字小的salve会优先考虑提升为master，所以例如有三个slave优先级分别为10，100，25，</div><div class="line"># 哨兵将挑选优先级最小数字为10的slave。</div><div class="line">#</div><div class="line"># 0作为一个特殊的优先级，标识这个slave不能作为master，所以一个优先级为0的slave永远不会被</div><div class="line"># 哨兵挑选提升为master</div><div class="line">#</div><div class="line"># 默认优先级为100</div><div class="line">slave-priority 100</div><div class="line"></div><div class="line"># 如果master少于N个延时小于等于M秒的已连接slave，就可以停止接收写操作。</div><div class="line">#</div><div class="line"># N个slave需要是“oneline”状态</div><div class="line">#</div><div class="line"># 延时是以秒为单位，并且必须小于等于指定值，是从最后一个从slave接收到的ping（通常每秒发送）</div><div class="line"># 开始计数。</div><div class="line">#</div><div class="line"># This option does not GUARANTEES that N replicas will accept the write, but</div><div class="line"># will limit the window of exposure for lost writes in case not enough slaves</div><div class="line"># are available, to the specified number of seconds.</div><div class="line">#</div><div class="line"># 例如至少需要3个延时小于等于10秒的slave用下面的指令：</div><div class="line">#</div><div class="line"># min-slaves-to-write 3</div><div class="line"># min-slaves-max-lag 10</div><div class="line">#</div><div class="line"># 两者之一设置为0将禁用这个功能。</div><div class="line">#</div><div class="line"># 默认 min-slaves-to-write 值是0（该功能禁用）并且 min-slaves-max-lag 值是10。</div><div class="line"></div><div class="line">################################## SECURITY ###################################</div><div class="line"></div><div class="line"># 要求客户端在处理任何命令时都要验证身份和密码。</div><div class="line"># 这个功能在有你不信任的其它客户端能够访问redis服务器的环境里非常有用。</div><div class="line">#</div><div class="line"></div><div class="line"># 为了向后兼容的话这段应该注释掉。而且大多数人不需要身份验证(例如:它们运行在自己的服务器上)</div><div class="line"># </div><div class="line"># 警告：因为Redis太快了，所以外面的人可以尝试每秒150k的密码来试图破解密码。这意味着你需要</div><div class="line"># 一个高强度的密码，否则破解太容易了。</div><div class="line">#</div><div class="line"># requirepass foobared</div><div class="line"></div><div class="line"># 命令重命名</div><div class="line">#</div><div class="line"># 在共享环境下，可以为危险命令改变名字。比如，你可以为 CONFIG 改个其他不太容易猜到的名字，</div><div class="line"># 这样内部的工具仍然可以使用，而普通的客户端将不行。</div><div class="line">#</div><div class="line"># 例如：</div><div class="line">#</div><div class="line"># rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52</div><div class="line">#</div><div class="line"># 也可以通过改名为空字符串来完全禁用一个命令</div><div class="line">#</div><div class="line"># rename-command CONFIG &quot;&quot;</div><div class="line">#</div><div class="line"># 请注意：改变命令名字被记录到AOF文件或被传送到从服务器可能产生问题。</div><div class="line"></div><div class="line">################################### LIMITS ####################################</div><div class="line"></div><div class="line"># 设置最多同时连接的客户端数量。默认这个限制是10000个客户端，然而如果Redis服务器不能配置</div><div class="line"># 处理文件的限制数来满足指定的值，那么最大的客户端连接数就被设置成当前文件限制数减32（因</div><div class="line"># 为Redis服务器保留了一些文件描述符作为内部使用）</div><div class="line">#</div><div class="line"># 一旦达到这个限制，Redis会关闭所有新连接并发送错误&apos;max number of clients reached&apos;</div><div class="line">#</div><div class="line"># maxclients 10000</div><div class="line"></div><div class="line"># 不要用比设置的上限更多的内存。一旦内存使用达到上限，Redis会根据选定的回收策略（参见：</div><div class="line"># maxmemmory-policy）删除key</div><div class="line">#</div><div class="line"># 如果因为删除策略Redis无法删除key，或者策略设置为 &quot;noeviction&quot;，Redis会回复需要更</div><div class="line"># 多内存的错误信息给命令。例如，SET,LPUSH等等，但是会继续响应像Get这样的只读命令。</div><div class="line">#</div><div class="line"># 在使用Redis作为LRU缓存，或者为实例设置了硬性内存限制的时候（使用 &quot;noeviction&quot; 策略）</div><div class="line"># 的时候，这个选项通常事很有用的。</div><div class="line">#</div><div class="line"># 警告：当有多个slave连上达到内存上限的实例时，master为同步slave的输出缓冲区所需</div><div class="line"># 内存不计算在使用内存中。这样当驱逐key时，就不会因网络问题 / 重新同步事件触发驱逐key</div><div class="line"># 的循环，反过来slaves的输出缓冲区充满了key被驱逐的DEL命令，这将触发删除更多的key，</div><div class="line"># 直到这个数据库完全被清空为止</div><div class="line"># </div><div class="line"># 总之...如果你需要附加多个slave，建议你设置一个稍小maxmemory限制，这样系统就会有空闲</div><div class="line"># 的内存作为slave的输出缓存区(但是如果最大内存策略设置为&quot;noeviction&quot;的话就没必要了)</div><div class="line">#</div><div class="line"># maxmemory &lt;bytes&gt;</div><div class="line"></div><div class="line"># 最大内存策略：如果达到内存限制了，Redis如何选择删除key。你可以在下面五个行为里选：</div><div class="line"># </div><div class="line"># volatile-lru -&gt; 根据LRU算法生成的过期时间来删除。</div><div class="line"># allkeys-lru -&gt; 根据LRU算法删除任何key。</div><div class="line"># volatile-random -&gt; 根据过期设置来随机删除key。 </div><div class="line"># allkeys-&gt;random -&gt; 无差别随机删。 </div><div class="line"># volatile-ttl -&gt; 根据最近过期时间来删除（辅以TTL） </div><div class="line"># noeviction -&gt; 谁也不删，直接在写操作时返回错误。</div><div class="line"># </div><div class="line"># 注意：对所有策略来说，如果Redis找不到合适的可以删除的key都会在写操作时返回一个错误。</div><div class="line">#</div><div class="line"></div><div class="line">#       目前为止涉及的命令：set setnx setex append</div><div class="line">#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd</div><div class="line">#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby</div><div class="line">#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby</div><div class="line">#       getset mset msetnx exec sort</div><div class="line">#</div><div class="line"></div><div class="line"># 默认值如下：</div><div class="line">#</div><div class="line"># maxmemory-policy volatile-lru</div><div class="line"></div><div class="line"># LRU和最小TTL算法的实现都不是很精确，但是很接近（为了省内存），所以你可以用样本量做检测。</div><div class="line"># 例如：默认Redis会检查3个key然后取最旧的那个，你可以通过下面的配置指令来设置样本的个数。</div><div class="line">#</div><div class="line"># maxmemory-samples 3</div><div class="line"></div><div class="line">############################## APPEND ONLY MODE ###############################</div><div class="line"></div><div class="line"># 默认情况下，Redis是异步的把数据导出到磁盘上。这种模式在很多应用里已经足够好，但Redis进程</div><div class="line"># 出问题或断电时可能造成一段时间的写操作丢失(这取决于配置的save指令)。</div><div class="line">#</div><div class="line"># AOF是一种提供了更可靠的替代持久化模式，例如使用默认的数据写入文件策略（参见后面的配置）</div><div class="line"># 在遇到像服务器断电或单写情况下Redis自身进程出问题但操作系统仍正常运行等突发事件时，Redis</div><div class="line"># 能只丢失1秒的写操作。</div><div class="line">#</div><div class="line"># AOF和RDB持久化能同时启动并且不会有问题。</div><div class="line"># 如果AOF开启，那么在启动时Redis将加载AOF文件，它更能保证数据的可靠性。</div><div class="line">#</div><div class="line"># 请查看 http://redis.io/topics/persistence 来获取更多信息.</div><div class="line"></div><div class="line">appendonly no</div><div class="line"></div><div class="line"># 纯累加文件名字（默认：&quot;appendonly.aof&quot;）</div><div class="line"></div><div class="line">appendfilename &quot;appendonly.aof&quot;</div><div class="line"></div><div class="line"># fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。</div><div class="line"># 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。</div><div class="line">#</div><div class="line"># Redis支持三种不同的模式：</div><div class="line">#</div><div class="line"># no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。</div><div class="line"># always：每次写操作都立刻写入到aof文件。慢，但是最安全。</div><div class="line"># everysec：每秒写一次。折中方案。 </div><div class="line">#</div><div class="line"># 默认的 &quot;everysec&quot; 通常来说能在速度和数据安全性之间取得比较好的平衡。根据你的理解来</div><div class="line"># 决定，如果你能放宽该配置为&quot;no&quot; 来获取更好的性能(但如果你能忍受一些数据丢失，可以考虑使用</div><div class="line"># 默认的快照持久化模式)，或者相反，用“always”会比较慢但比everysec要更安全。</div><div class="line">#</div><div class="line"># 请查看下面的文章来获取更多的细节</div><div class="line"># http://antirez.com/post/redis-persistence-demystified.html </div><div class="line"># </div><div class="line"># 如果不能确定，就用 &quot;everysec&quot;</div><div class="line"></div><div class="line"># appendfsync always</div><div class="line">appendfsync everysec</div><div class="line"># appendfsync no</div><div class="line"></div><div class="line"># 如果AOF的同步策略设置成 &quot;always&quot; 或者 &quot;everysec&quot;，并且后台的存储进程（后台存储或写入AOF</div><div class="line"># 日志）会产生很多磁盘I/O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。</div><div class="line"># 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。</div><div class="line">#</div><div class="line"># 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止fsync()。</div><div class="line"># </div><div class="line"># 这就意味着如果有子进程在进行保存操作，那么Redis就处于&quot;不可同步&quot;的状态。</div><div class="line"># 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定）</div><div class="line"># </div><div class="line"># 如果把这个设置成&quot;yes&quot;带来了延迟问题，就保持&quot;no&quot;，这是保存持久数据的最安全的方式。</div><div class="line"></div><div class="line">no-appendfsync-on-rewrite no</div><div class="line"></div><div class="line"># 自动重写AOF文件</div><div class="line"># 如果AOF日志文件增大到指定百分比，Redis能够通过 BGREWRITEAOF 自动重写AOF日志文件。</div><div class="line"># </div><div class="line"># 工作原理：Redis记住上次重写时AOF文件的大小（如果重启后还没有写操作，就直接用启动时的AOF大小）</div><div class="line"># </div><div class="line"># 这个基准大小和当前大小做比较。如果当前大小超过指定比例，就会触发重写操作。你还需要指定被重写</div><div class="line"># 日志的最小尺寸，这样避免了达到指定百分比但尺寸仍然很小的情况还要重写。</div><div class="line">#</div><div class="line"># 指定百分比为0会禁用AOF自动重写特性。</div><div class="line"></div><div class="line">auto-aof-rewrite-percentage 100</div><div class="line">auto-aof-rewrite-min-size 64mb</div><div class="line"></div><div class="line">################################ LUA SCRIPTING  ###############################</div><div class="line"></div><div class="line"># Lua 脚本的最大执行时间，毫秒为单位</div><div class="line">#</div><div class="line"># 如果达到了最大的执行时间，Redis将要记录在达到最大允许时间之后一个脚本仍然在执行，并且将</div><div class="line"># 开始对查询进行错误响应。</div><div class="line">#</div><div class="line"># 当一个长时间运行的脚本超过了最大执行时间，只有 SCRIPT KILL 和 SHUTDOWN NOSAVE 两个</div><div class="line"># 命令可用。第一个可以用于停止一个还没有调用写命名的脚本。第二个是关闭服务器唯一方式，当</div><div class="line"># 写命令已经通过脚本开始执行，并且用户不想等到脚本的自然终止。</div><div class="line">#</div><div class="line"># 设置成0或者负值表示不限制执行时间并且没有任何警告</div><div class="line">lua-time-limit 5000</div><div class="line"></div><div class="line">################################## SLOW LOG ###################################</div><div class="line"></div><div class="line"># Redis慢查询日志可以记录超过指定时间的查询。运行时间不包括各种I/O时间，例如：连接客户端，</div><div class="line"># 发送响应数据等，而只计算命令执行的实际时间（这只是线程阻塞而无法同时为其他请求服务的命令执</div><div class="line"># 行阶段）</div><div class="line"># </div><div class="line"># 你可以为慢查询日志配置两个参数:一个指明Redis的超时时间(单位为微秒)来记录超过这个时间的命令</div><div class="line"># 另一个是慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录从队列中移除。</div><div class="line">#</div><div class="line"># 下面的时间单位是微秒，所以1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录</div><div class="line"># 所有命令。</div><div class="line">slowlog-log-slower-than 10000</div><div class="line"></div><div class="line"># 这个长度没有限制。只是要主要会消耗内存。你可以通过 SLOWLOG RESET 来回收内存。</div><div class="line">slowlog-max-len 128</div><div class="line"></div><div class="line">############################# Event notification ##############################</div><div class="line"></div><div class="line"># Redis 能通知 Pub/Sub 客户端关于键空间发生的事件</div><div class="line"># 这个功能文档位于http://redis.io/topics/keyspace-events</div><div class="line">#</div><div class="line"># 例如：如果键空间事件通知被开启，并且客户端对 0 号数据库的键 foo 执行 DEL 命令时，将通过</div><div class="line"># Pub/Sub发布两条消息：</div><div class="line"># PUBLISH __keyspace@0__:foo del</div><div class="line"># PUBLISH __keyevent@0__:del foo</div><div class="line">#</div><div class="line"># 可以在下表中选择Redis要通知的事件类型。事件类型由单个字符来标识：</div><div class="line">#</div><div class="line"># K    键空间通知，以__keyspace@&lt;db&gt;__为前缀</div><div class="line"># E    键事件通知，以__keysevent@&lt;db&gt;__为前缀</div><div class="line"># g    DEL , EXPIRE , RENAME 等类型无关的通用命令的通知, ...</div><div class="line"># $    String命令</div><div class="line"># l    List命令</div><div class="line"># s    Set命令</div><div class="line"># h    Hash命令</div><div class="line"># z    有序集合命令</div><div class="line"># x    过期事件（每次key过期时生成）</div><div class="line"># e    驱逐事件（当key在内存满了被清除时生成）</div><div class="line"># A    g$lshzxe的别名，因此”AKE”意味着所有的事件</div><div class="line">#</div><div class="line"># notify-keyspace-events 带一个由0到多个字符组成的字符串参数。空字符串意思是通知被禁用。</div><div class="line">#</div><div class="line"># 例子：启用List和通用事件通知：</div><div class="line"># notify-keyspace-events Elg</div><div class="line">#</div><div class="line"># 例子2：为了获取过期key的通知订阅名字为 __keyevent@__:expired 的频道，用以下配置</div><div class="line"># notify-keyspace-events Ex</div><div class="line">#</div><div class="line"># 默认所用的通知被禁用，因为用户通常不需要该特性，并且该特性会有性能损耗。</div><div class="line"># 注意如果你不指定至少K或E之一，不会发送任何事件。</div><div class="line">notify-keyspace-events &quot;&quot;</div><div class="line"></div><div class="line">############################### ADVANCED CONFIG ###############################</div><div class="line"></div><div class="line"># 当hash只有少量的entry时，并且最大的entry所占空间没有超过指定的限制时，会用一种节省内存的</div><div class="line"># 数据结构来编码。可以通过下面的指令来设定限制</div><div class="line">hash-max-ziplist-entries 512</div><div class="line">hash-max-ziplist-value 64</div><div class="line"></div><div class="line"># 与hash似，数据元素较少的list，可以用另一种方式来编码从而节省大量空间。</div><div class="line"># 这种特殊的方式只有在符合下面限制时才可以用：</div><div class="line">list-max-ziplist-entries 512</div><div class="line">list-max-ziplist-value 64</div><div class="line"></div><div class="line"># set有一种特殊编码的情况：当set数据全是十进制64位有符号整型数字构成的字符串时。</div><div class="line"># 下面这个配置项就是用来设置set使用这种编码来节省内存的最大长度。</div><div class="line">set-max-intset-entries 512</div><div class="line"></div><div class="line"># 与hash和list相似，有序集合也可以用一种特别的编码方式来节省大量空间。</div><div class="line"># 这种编码只适合长度和元素都小于下面限制的有序集合：</div><div class="line">zset-max-ziplist-entries 128</div><div class="line">zset-max-ziplist-value 64</div><div class="line"></div><div class="line"># HyperLogLog sparse representation bytes limit. The limit includes the</div><div class="line"># 16 bytes header. When an HyperLogLog using the sparse representation crosses</div><div class="line"># this limit, it is converted into the dense representation.</div><div class="line">#</div><div class="line"># A value greater than 16000 is totally useless, since at that point the</div><div class="line"># dense representation is more memory efficient.</div><div class="line"># </div><div class="line"># The suggested value is ~ 3000 in order to have the benefits of</div><div class="line"># the space efficient encoding without slowing down too much PFADD,</div><div class="line"># which is O(N) with the sparse encoding. The value can be raised to</div><div class="line"># ~ 10000 when CPU is not a concern, but space is, and the data set is</div><div class="line"># composed of many HyperLogLogs with cardinality in the 0 - 15000 range.</div><div class="line">hll-sparse-max-bytes 3000</div><div class="line"></div><div class="line"># 启用哈希刷新，每100个CPU毫秒会拿出1个毫秒来刷新Redis的主哈希表（顶级键值映射表）。</div><div class="line"># redis所用的哈希表实现（见dict.c）采用延迟哈希刷新机制：你对一个哈希表操作越多，哈希刷新</div><div class="line"># 操作就越频繁；反之，如果服务器是空闲的，那么哈希刷新就不会完成，哈希表就会占用更多的一些</div><div class="line"># 内存而已。</div><div class="line"># </div><div class="line"># 默认是每秒钟进行10次哈希表刷新，用来刷新字典，然后尽快释放内存。</div><div class="line">#</div><div class="line"># 建议：</div><div class="line"># 如果你对延迟比较在意，不能够接受Redis时不时的对请求有2毫秒的延迟的话，就用</div><div class="line"># &quot;activerehashing no&quot;，如果不太在意延迟而希望尽快释放内存就设置&quot;activerehashing yes&quot;</div><div class="line">activerehashing yes</div><div class="line"></div><div class="line"># 客户端的输出缓冲区的限制，可用于强制断开那些因为某种原因从服务器读取数据的速度不够快的客户端，</div><div class="line"># （一个常见的原因是一个发布/订阅客户端消费消息的速度无法赶上生产它们的速度）</div><div class="line">#</div><div class="line"># 可以对三种不同的客户端设置不同的限制：</div><div class="line"># normal -&gt; 正常客户端</div><div class="line"># slave -&gt; slave和 MONITOR 客户端</div><div class="line"># pubsub -&gt; 至少订阅了一个pubsub channel或pattern的客户端</div><div class="line">#</div><div class="line"># 下面是每个client-output-buffer-limit语法:</div><div class="line"># client-output-buffer-limit &lt;class&gt;&lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;</div><div class="line"></div><div class="line"># 一旦达到硬限制客户端会立即被断开，或者达到软限制并持续达到指定的秒数（连续的）。</div><div class="line"># 例如，如果硬限制为32兆字节和软限制为16兆字节/10秒，客户端将会立即断开</div><div class="line"># 如果输出缓冲区的大小达到32兆字节，或客户端达到16兆字节并连续超过了限制10秒，就将断开连接。</div><div class="line">#</div><div class="line"># 默认normal客户端不做限制，因为他们在不主动请求时不接收数据（以推的方式），只有异步客户端</div><div class="line"># 可能会出现请求数据的速度比它可以读取的速度快的场景。</div><div class="line">#</div><div class="line"># pubsub和slave客户端会有一个默认值，因为订阅者和slaves以推的方式来接收数据</div><div class="line">#</div><div class="line"># 把硬限制和软限制都设置为0来禁用该功能</div><div class="line">client-output-buffer-limit normal 0 0 0</div><div class="line">client-output-buffer-limit slave 256mb 64mb 60</div><div class="line">client-output-buffer-limit pubsub 32mb 8mb 60</div><div class="line"></div><div class="line"># Redis调用内部函数来执行许多后台任务，如关闭客户端超时的连接，清除未被请求过的过期Key等等。</div><div class="line">#</div><div class="line"># 不是所有的任务都以相同的频率执行，但Redis依照指定的“hz”值来执行检查任务。</div><div class="line">#</div><div class="line"># 默认情况下，“hz”的被设定为10。提高该值将在Redis空闲时使用更多的CPU时，但同时当有多个key</div><div class="line"># 同时到期会使Redis的反应更灵敏，以及超时可以更精确地处理。</div><div class="line">#</div><div class="line"># 范围是1到500之间，但是值超过100通常不是一个好主意。</div><div class="line"># 大多数用户应该使用10这个默认值，只有在非常低的延迟要求时有必要提高到100。</div><div class="line">hz 10</div><div class="line"></div><div class="line"># 当一个子进程重写AOF文件时，如果启用下面的选项，则文件每生成32M数据会被同步。为了增量式的</div><div class="line"># 写入硬盘并且避免大的延迟高峰这个指令是非常有用的</div><div class="line">aof-rewrite-incremental-fsync yes</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/di
    
    </summary>
    
      <category term="redis" scheme="http://yoursite.com/categories/redis/"/>
    
    
      <category term="redis" scheme="http://yoursite.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>maven打包替换配置文件</title>
    <link href="http://yoursite.com/2017/08/30/maven%E6%89%93%E5%8C%85%E6%9B%BF%E6%8D%A2%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"/>
    <id>http://yoursite.com/2017/08/30/maven打包替换配置文件/</id>
    <published>2017-08-30T01:53:00.000Z</published>
    <updated>2017-08-30T01:54:58.793Z</updated>
    
    <content type="html"><![CDATA[<h2 id="maven打包替换文件"><a href="#maven打包替换文件" class="headerlink" title="maven打包替换文件"></a>maven打包替换文件</h2><hr>
<blockquote>
<p><strong>maven</strong>不同环境替换不同配置文件，使用filters文件夹下<code>测试环境</code>，<code>开发环境</code>，<code>生产环境</code>配置文件替换打包，主要用到<code>maven-war-plugin</code>，<code>profile</code>.</p>
</blockquote>
<h3 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h3><blockquote>
<p> 开发环境</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;profile&gt;</div><div class="line">    &lt;!-- 本地开发环境 --&gt;</div><div class="line">    &lt;id&gt;dev&lt;/id&gt;</div><div class="line">    &lt;properties&gt;</div><div class="line">        &lt;package.environment&gt;dev&lt;/package.environment&gt;</div><div class="line">    &lt;/properties&gt;</div><div class="line">    &lt;activation&gt;</div><div class="line">        &lt;！--默认环境--&gt;</div><div class="line">        &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;</div><div class="line">    &lt;/activation&gt;</div><div class="line">&lt;/profile&gt;</div></pre></td></tr></table></figure>
<blockquote>
<p>测试环境</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&lt;profile&gt;</div><div class="line">    &lt;!-- 测试环境 --&gt;</div><div class="line">    &lt;id&gt;test&lt;/id&gt;</div><div class="line">    &lt;properties&gt;</div><div class="line">        &lt;package.environment&gt;test&lt;/package.environment&gt;</div><div class="line">    &lt;/properties&gt;</div><div class="line">&lt;/profile&gt;</div></pre></td></tr></table></figure>
<blockquote>
<p>生产环境<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&lt;profile&gt;</div><div class="line">    &lt;!-- 生产环境 --&gt;</div><div class="line">    &lt;id&gt;prod&lt;/id&gt;</div><div class="line">    &lt;properties&gt;</div><div class="line">        &lt;package.environment&gt;prod&lt;/package.environment&gt;</div><div class="line">    &lt;/properties&gt;</div><div class="line">&lt;/profile&gt;</div></pre></td></tr></table></figure></p>
</blockquote>
<h1 id="maven-war-plugin"><a href="#maven-war-plugin" class="headerlink" title="maven war plugin"></a>maven war plugin</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">&lt;plugin&gt;</div><div class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;$&#123;war-version&#125;&lt;/version&gt;</div><div class="line">    &lt;configuration&gt;</div><div class="line">        &lt;warName&gt;ROOT&lt;/warName&gt;</div><div class="line">        &lt;webResources&gt;</div><div class="line">            &lt;resource&gt;</div><div class="line">                &lt;directory&gt;filters/$&#123;package.environment&#125;/properties&lt;/directory&gt;</div><div class="line">                &lt;targetPath&gt;WEB-INF/classes&lt;/targetPath&gt;</div><div class="line">                &lt;filtering&gt;true&lt;/filtering&gt;</div><div class="line">            &lt;/resource&gt;</div><div class="line">            &lt;resource&gt;</div><div class="line">                &lt;directory&gt;filters/$&#123;package.environment&#125;/common&lt;/directory&gt;</div><div class="line">                &lt;targetPath&gt;Contents&lt;/targetPath&gt;</div><div class="line">                &lt;filtering&gt;true&lt;/filtering&gt;</div><div class="line">            &lt;/resource&gt;</div><div class="line">        &lt;/webResources&gt;</div><div class="line">    &lt;/configuration&gt;</div><div class="line">&lt;/plugin&gt;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;maven打包替换文件&quot;&gt;&lt;a href=&quot;#maven打包替换文件&quot; class=&quot;headerlink&quot; title=&quot;maven打包替换文件&quot;&gt;&lt;/a&gt;maven打包替换文件&lt;/h2&gt;&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;maven&lt;/s
    
    </summary>
    
    
      <category term="maven" scheme="http://yoursite.com/tags/maven/"/>
    
  </entry>
  
  <entry>
    <title>Springboot(一)</title>
    <link href="http://yoursite.com/2017/08/24/Springboot-%E4%B8%80/"/>
    <id>http://yoursite.com/2017/08/24/Springboot-一/</id>
    <published>2017-08-24T05:29:00.000Z</published>
    <updated>2017-08-24T05:30:04.675Z</updated>
    
    <content type="html"><![CDATA[<p>什么是spring boot</p>
<p>Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。用我的话来理解，就是spring boot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像maven整合了所有的jar包，spring boot整合了所有的框架（不知道这样比喻是否合适）。</p>
<p>使用spring boot有什么好处</p>
<p>其实就是简单、快速、方便！平时如果我们需要搭建一个spring web项目的时候需要怎么做呢？</p>
<p>1）配置web.xml，加载spring和spring mvc<br>2）配置数据库连接、配置spring事务<br>3）配置加载配置文件的读取，开启注解<br>4）配置日志文件<br>…<br>配置完成之后部署tomcat 调试<br>…<br>现在非常流行微服务，如果我这个项目仅仅只是需要发送一个邮件，如果我的项目仅仅是生产一个积分；我都需要这样折腾一遍!</p>
<p>但是如果使用spring boot呢？<br>很简单，我仅仅只需要非常少的几个配置就可以迅速方便的搭建起来一套web项目或者是构建一个微服务！</p>
<p>使用sping boot到底有多爽，用下面这幅图来表达</p>
<p>快速入门</p>
<p>说了那么多，手痒痒的很，马上来一发试试!</p>
<p>maven构建项目</p>
<p>1、访问<a href="http://start.spring.io/" target="_blank" rel="external">http://start.spring.io/</a><br>2、选择构建工具Maven Project、Spring Boot版本1.3.6以及一些工程基本信息，点击“Switch to the full version.”java版本选择1.7，可参考下图所示：</p>
<p>3、点击Generate Project下载项目压缩包<br>4、解压后，使用eclipse，Import -&gt; Existing Maven Projects -&gt; Next -&gt;选择解压后的文件夹-&gt; Finsh，OK done!<br>项目结构介绍</p>
<p>如上图所示，Spring Boot的基础结构共三个文件:</p>
<p>src/main/java 程序开发以及主程序入口<br>src/main/resources 配置文件<br>src/test/java 测试程序<br>另外，spingboot建议的目录结果如下：<br>root package结构：com.example.myproject</p>
<p>com<br>  +- example<br>    +- myproject<br>      +- Application.java<br>      |<br>      +- domain<br>      |  +- Customer.java<br>      |  +- CustomerRepository.java<br>      |<br>      +- service<br>      |  +- CustomerService.java<br>      |<br>      +- controller<br>      |  +- CustomerController.java<br>      |<br>1、Application.java 建议放到跟目录下面,主要用于做一些框架配置<br>2、domain目录主要用于实体（Entity）与数据访问层（Repository）<br>3、service 层主要是业务类代码<br>4、controller 负责页面访问控制<br>采用默认配置可以省去很多配置，当然也可以根据自己的喜欢来进行更改<br>最后，启动Application main方法，至此一个java项目搭建好了！</p>
<p>引入web模块</p>
<p>1、pom.xml中添加支持web的模块：</p>
<p><dependency><br>        <groupid>org.springframework.boot</groupid><br>        <artifactid>spring-boot-starter-web</artifactid><br> </dependency><br>pom.xml文件中默认有两个模块：</p>
<p>spring-boot-starter ：核心模块，包括自动配置支持、日志和YAML；</p>
<p>spring-boot-starter-test ：测试模块，包括JUnit、Hamcrest、Mockito。</p>
<p>2、编写controller内容：</p>
<p>@RestController<br>public class HelloWorldController {<br>    @RequestMapping(“/hello”)<br>    public String index() {<br>        return “Hello World”;<br>    }<br>}<br>@RestController 的意思就是controller里面的方法都以json格式输出，不用再写什么jackjson配置的了！</p>
<p>3、启动主程序，打开浏览器访问<a href="http://localhost:8080/hello，就可以看到效果了，有木有很简单！" target="_blank" rel="external">http://localhost:8080/hello，就可以看到效果了，有木有很简单！</a></p>
<p>如何做单元测试</p>
<p>打开的src/test/下的测试入口，编写简单的http请求来测试；使用mockmvc进行，利用MockMvcResultHandlers.print()打印出执行结果。</p>
<p>@RunWith(SpringJUnit4ClassRunner.class)<br>@SpringApplicationConfiguration(classes = MockServletContext.class)<br>@WebAppConfiguration<br>public class HelloWorldControlerTests {<br>    private MockMvc mvc;<br>    @Before<br>    public void setUp() throws Exception {<br>        mvc = MockMvcBuilders.standaloneSetup(new HelloWorldController()).build();<br>    }<br>    @Test<br>    public void getHello() throws Exception {<br>    mvc.perform(MockMvcRequestBuilders.get(“/hello”).accept(MediaType.APPLICATION_JSON))<br>                .andExpect(MockMvcResultMatchers.status().isOk())<br>                .andDo(MockMvcResultHandlers.print())<br>                .andReturn();<br>    }<br>}<br>开发环境的调试</p>
<p>热启动在正常开发项目中已经很常见了吧，虽然平时开发web项目过程中，改动项目启重启总是报错；但springBoot对调试支持很好，修改之后可以实时生效，需要添加以下的配置：</p>
 <dependencies><br>    <dependency><br>        <groupid>org.springframework.boot</groupid><br>        <artifactid>spring-boot-devtools</artifactid><br>        <optional>true</optional><br>    </dependency><br></dependencies>

<p><build><br>    <plugins><br>        <plugin><br>            <groupid>org.springframework.boot</groupid><br>            <artifactid>spring-boot-maven-plugin</artifactid><br>            <configuration><br>                <fork>true</fork><br>            </configuration><br>        </plugin><br></plugins><br></build><br>该模块在完整的打包环境下运行的时候会被禁用。如果你使用java -jar启动应用或者用一个特定的classloader启动，它会认为这是一个“生产环境”。</p>
<p>总结</p>
<p>使用spring boot可以非常方便、快速搭建项目，使我们不用关心框架之间的兼容性，适用版本等各种问题，我们想使用任何东西，仅仅添加一个配置就可以，所以使用sping boot非常适合构建微服务。</p>
<p>文中所有的代码<a href="https://github.com/ityouknow/spring-boot-starter" target="_blank" rel="external">https://github.com/ityouknow/spring-boot-starter</a></p>
<p>作者：纯洁的微笑<br>出处：www.ityouknow.com<br>版权所有，欢迎保留原文链接进行转载：)</p>
<p>作者：纯洁的虫纸<br>链接：<a href="http://www.jianshu.com/p/1d6b0b20f20d" target="_blank" rel="external">http://www.jianshu.com/p/1d6b0b20f20d</a><br>來源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;什么是spring boot&lt;/p&gt;
&lt;p&gt;Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。用我的话来理解，就是spring 
    
    </summary>
    
      <category term="springboot" scheme="http://yoursite.com/categories/springboot/"/>
    
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>Linux运维完全入门指南</title>
    <link href="http://yoursite.com/2017/08/24/Linux%E8%BF%90%E7%BB%B4%E5%AE%8C%E5%85%A8%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://yoursite.com/2017/08/24/Linux运维完全入门指南/</id>
    <published>2017-08-24T05:27:00.000Z</published>
    <updated>2017-08-24T05:28:07.617Z</updated>
    
    <content type="html"><![CDATA[<p>前几天整理了一下自己入门时候搜集的资料，一边整理一边回忆。</p>
<p>那时候我还是个小白，用虚拟机装了个CentOS系统来玩，但是总也装不上，在论坛上求助也没人理。半天终于有个人说在某网站看过这个问题，我又找了大半天才找到这个网站，最后也还是没解决问题。就这样，一个系统装了一天半。</p>
<p>对于初学者，特别是从未接触过深度计算机知识的小白，搜集资料的时间甚至要占到学习时间的一半以上，学起来慢也大都是因为这一点。</p>
<p>正好资料我也都整理好了，不如就发出来给大家看看。先说明，这里的东西都是些很浅显、只适合小白的东西。毕竟要看高阶内容的人，应该也有能力自己去快速发掘资料了。</p>
<p>基础入门</p>
<p>系统简介</p>
<p>Linux系统结构 详解来源：CSDN博客<br>Linux架构来源：博客园<br>Linux百度百科来源：百度百科<br>为一般人解说什么是Linux来源：马哥Linux运维<br>系统安装</p>
<p>新手指南： 手把手教你安装 Ubuntu 和 Fedora 来源:Linux中国<br>在UEFI模式下安装Ubuntu 14.04与Windows 8/8.1双启动 来源：Linux中国<br>linux系统安装详细图文教程来源：CSDN<br>虚拟机安装Linux系统图文教程来源：百度经验<br>常用命令</p>
<p>Linux常用命令大全来源：马哥Linux运维<br>初窥Linux 之 我最常用的20条命令来源：CSDN博客<br>Linux常用命令大全来源：Linux公社<br>软件包安装</p>
<p>在 Ubuntu 和 Fedora 上安装软件包来源：Linux中国<br>LINUX下安装软件方法命令方法来源：红黑联盟<br>Linux 平台上的软件包管理来源：IBMdeveloperWorks<br>Linux下RPM软件包的安装及卸载来源：51CTO<br>中级进阶</p>
<p>用户及用户组</p>
<p>Linux用户管理命令来源：Linux公社<br>Linux的用户和用户组管理来源：博客园<br>Linux 用户和用户组管理来源：菜鸟教程<br>权限管理</p>
<p>linux权限管理 来源：Chinaunix<br>Linux权限管理来源：博客园<br>普通权限及umask来源：马哥Linux运维<br>linux普通用户获取管理员权限来源：博客园<br>网络相关</p>
<p>linux下的基本网络配置来源：红黑联盟<br>Linux常用的网络命令来源：博客园<br>linux网络配置来源：百度经验<br>服务器基础</p>
<p>Linux下LAMP（Apache+PHP+MySql）环境配置来源：博客园<br>Linux下安装Nginx详细图解教程来源：CSDN博客<br>Linux虚拟机下安装配置MySQL来源：Linux中国<br>服务器安全</p>
<p>Linux 服务器安全技巧来源：Linux中国<br>Linux强化论：15步打造一个安全的Linux服务器来源：REEBUF<br>原创投稿 | 防火墙及NAT服务来源：马哥原创作者胖猴<br>高阶技巧</p>
<p>正如前文所说，需要高级内容的用户应该已经有了找到资源的方法，所以这里会暂时空置。<br>当然，以后有时间我会一点点搬运过来，但现在还是专注于初级知识吧。</p>
<p>学习资料</p>
<p>这里我会推荐一些文字或者视频，仍然专注于小白的入门知识。<br>为了避免广告嫌疑，我将不附带链接。<br>我所推荐的所有的书籍资料你都可以在亚马逊或者其他渠道获得。<br>我所推荐的所有视频资料都是免费的。</p>
<p>以下是推荐资料：</p>
<p>各发行版使用手册<br>《鸟哥的Linux私房菜》<br>《Linux命令行与shell脚本编程大全》<br>《马哥带你学Linux从入门到精通》<br>网络社区</p>
<p>我不准备在这里进行细分，我认为你有足够的能力分辨什么是社区、资讯站、博客、论坛等等形式，所以我把它们全部都放在这里了。<br>同时我要申明，排名不分先后，想起哪个写那个。</p>
<p>Linux中国<br>CSDN<br>ChinaUnix<br>博客园<br>51CTO<br>腾讯课堂<br>网易云课堂<br>百度传课<br>LinuxOnline(英文)<br>各发行版官网<br>结语</p>
<p>入门级别的资料已经整理的差不多了。<br>当然，受限于个人的学习经历、使用习惯的等问题，可能还有很多非常棒的学习资料我没有整理出来，欢迎大家补充。<br>对入门级别的新人我还是有话想说：<br>虽然这篇文章整理了比较多的资料，但是别急着收藏。贪多嚼不烂，如果你手上有正在学习的内容，先把它学完。<br>在学习的过程中，尝试判断内容对自己的价值，因为很可能于我价值连城的东西，对你而言却如敝履。</p>
<p>作者：JokerW<br>链接：<a href="http://www.jianshu.com/p/9a7f1f3d0317" target="_blank" rel="external">http://www.jianshu.com/p/9a7f1f3d0317</a><br>來源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前几天整理了一下自己入门时候搜集的资料，一边整理一边回忆。&lt;/p&gt;
&lt;p&gt;那时候我还是个小白，用虚拟机装了个CentOS系统来玩，但是总也装不上，在论坛上求助也没人理。半天终于有个人说在某网站看过这个问题，我又找了大半天才找到这个网站，最后也还是没解决问题。就这样，一个系统
    
    </summary>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Nginx从听说到学会</title>
    <link href="http://yoursite.com/2017/08/24/Nginx%E4%BB%8E%E5%90%AC%E8%AF%B4%E5%88%B0%E5%AD%A6%E4%BC%9A/"/>
    <id>http://yoursite.com/2017/08/24/Nginx从听说到学会/</id>
    <published>2017-08-24T05:22:00.000Z</published>
    <updated>2017-08-24T05:24:40.106Z</updated>
    
    <content type="html"><![CDATA[<h3 id="第一章-Nginx简介"><a href="#第一章-Nginx简介" class="headerlink" title="第一章 Nginx简介"></a>第一章 Nginx简介</h3><h3 id="Nginx是什么"><a href="#Nginx是什么" class="headerlink" title="Nginx是什么"></a>Nginx是什么</h3><p>没有听过Nginx？那么一定听过它的“同行”Apache吧！Nginx同Apache一样都是一种WEB服务器。基于REST架构风格，以统一资源描述符(Uniform Resources Identifier)URI或者统一资源定位符(Uniform Resources Locator)URL作为沟通依据，通过HTTP协议提供各种网络服务。</p>
<p>然而，这些服务器在设计之初受到当时环境的局限，例如当时的用户规模，网络带宽，产品特点等局限并且各自的定位和发展都不尽相同。这也使得各个WEB服务器有着各自鲜明的特点。</p>
<p>Apache的发展时期很长，而且是毫无争议的世界第一大服务器。它有着很多有点：稳定、开源、跨平台等等。但是由于它出现的时间太长了。它兴起的年代，互联网产业远比不上现在。所以它被设计为一个重量级的。不支持高并发的服务器。在Apache上运行数以万计的并发访问，会导致服务器消耗大量内存。操作系统对其进行进程或线程间的切换也消耗了大量的CPU资源，导致HTTP请求的平均响应速度降低。</p>
<p>这些都决定了Apache不可能成为高性能WEB服务器，轻量级高并发服务器Nginx和Lighttpd就应运而生了。</p>
<p>Nginx产生</p>
<p>又是拜大神的时候了，这次被选中的人是俄罗斯的工程师Igor Sysoev，他在为Rambler Media工作期间，使用C语言开发了Nginx。Nginx作为WEB服务器一直为Rambler Media提供出色而又稳定的服务。</p>
<p>然后呢，Igor Sysoev将Nginx代码开源，并且赋予自由软件许可证。</p>
<p>由于：</p>
<p>Nginx使用基于事件驱动架构，使得其可以支持数以百万级别的TCP连接<br>高度的模块化和自由软件许可证是的第三方模块层出不穷（这是个开源的时代啊~）<br>Nginx是一个跨平台服务器，可以运行在Linux, FreeBSD, Solaris, AIX, Mac OS, Windows等操作系统上<br>这些优秀的设计带来的极大的稳定性。<br>于是，duang的一下。Nginx火了。</p>
<p>三大WEB服务器对比</p>
<p>lighttpd</p>
<p>Lighttpd是一个具有非常低的内存开销，cpu占用率低，效能好，以及丰富的模块等特点。lighttpd是众多OpenSource轻量级的web server中较为优秀的一个。支持FastCGI, CGI, Auth, 输出压缩(output compress), URL重写, Alias等重要功能。</p>
<p>Lighttpd使用fastcgi方式运行PHP,它会使用很少的PHP进程响应很大的并发量。</p>
<p>Fastcgi的优点在于：</p>
<p>从稳定性上看, fastcgi是以独立的进程池运行来cgi,单独一个进程死掉,系统可以很轻易的丢弃,然后重新分配新的进程来运行逻辑.<br>从安全性上看, fastcgi和宿主的server完全独立, fastcgi怎么down也不会把server搞垮,<br>从性能上看, fastcgi把动态逻辑的处理从server中分离出来, 大负荷的IO处理还是留给宿主server, 这样宿主server可以一心一意作IO,对于一个普通的动态网页来说, 逻辑处理可能只有一小部分, 大量的图片等静态IO处理完全不需要逻辑程序的参与<br>从扩展性上讲, fastcgi是一个中立的技术标准, 完全可以支持任何语言写的处理程序php,Java,Python<br>Apache</p>
<p>apache是世界排名第一的web服务器, 根据netcraft所作的调查,世界上百分之五十以上的web服务器在使用apache.</p>
<p>1995年4月, 最早的apache(0.6.2版)由apache group公布发行. apache group 是一个完全通过internet进行运作的非盈利机构, 由它来决定apache web服务器的标准发行版中应该包含哪些内容. 准许任何人修改隐错, 提供新的特征和将它移植到新的平台上, 以及其它的工作. 当新的代码被提交给apache group时, 该团体审核它的具体内容, 进行测试 如果认为满意, 该代码就会被集成到apache的主要发行版中。</p>
<p>apache 的特性:</p>
<p>几乎可以运行在所有的计算机平台上<br>支持最新的http/1.1协议<br>简单而且强有力的基于文件的配置(httpd.conf)<br>支持通用网关接口(cgi)<br>支持虚拟主机<br>支持http认证<br>集成perl<br>集成的代理服务器<br>可以通过web浏览器监视服务器的状态, 可以自定义日志<br>支持服务器端包含命令(ssi)<br>支持安全socket层(ssl)<br>具有用户会话过程的跟踪能力<br>支持fastcgi<br>支持Java<br>Nginx</p>
<p>Nginx是俄罗斯人编写的十分轻量级的HTTP服务器,Nginx，它的发音为“engine X”， 是一个高性能的HTTP和反向代理服务器，同时也是一个IMAP/POP3/SMTP 代理服务器．Nginx是由俄罗斯人 Igor Sysoev为俄罗斯访问量第二的 Rambler.ru站点开发.</p>
<p>Nginx以事件驱动的方式编写，所以有非常好的性能，同时也是一个非常高效的反向代理、负载平衡。其拥有匹配 Lighttpd的性能，同时还没有Lighttpd的内存泄漏问题，而且Lighttpd的mod_proxy也有一些问题并且很久没有更新。但是Nginx并不支持cgi方式运行，原因是可以减少因此带来的一些程序上的漏洞。所以必须使用FastCGI方式来执行PHP程序。</p>
<p>nginx做为HTTP服务器，有以下几项基本特性：</p>
<p>处理静态文件，索引文件以及自动索引；打开文件描述符缓冲<br>无缓存的反向代理加速，简单的负载均衡和容错<br>FastCGI，简单的负载均衡和容错<br>模块化的结构。包括gzipping, byte ranges, chunked responses,以及 SSI-filter等filter。如果由FastCGI或其它代理服务器处理单页中存在的多个SSI，则这项处理可以并行运行，而不需要相互等待。<br>Nginx专为性能优化而开发，性能是其最重要的考量,实现上非常注重效率。它支持内核Poll模型，能经受高负载的考验,有报告表明能支持高达 50,000个并发连接数。</p>
<p>Nginx具有很高的稳定性。其它HTTP服务器，当遇到访问的峰值，或者有人恶意发起慢速连接时，也很可能会导致服务器物理内存耗尽频繁交换，失去响应，只能重启服务器。例如当前apache一旦上到200个以上进程，web响应速度就明显非常缓慢了。而Nginx采取了分阶段资源分配技术，使得它的CPU与内存占用率非常低。nginx官方表示保持10,000个没有活动的连接，它只占2.5M内存，所以类似DOS这样的攻击对nginx来说基本上是毫无用处的。就稳定性而言,nginx比lighthttpd更胜一筹。</p>
<p>Nginx支持热部署。它的启动特别容易, 并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在不间断服务的情况下，对软件版本进行进行升级。</p>
<p>三种服务器比较</p>
<p>server    Apache    Nginx    Lighttpd<br>Proxy代理    非常好    非常好    一般<br>Rewriter    好    非常好    一般<br>Fcgi    不好    好    非常好<br>热部署    不支持    支持    不支持<br>系统压力比较    很大    很小    比较小<br>稳定性    好    非常好    不好<br>安全性    好    一般    一般<br>静态文件处理    一般    非常好    好<br>反向代理    一般    非常好    一般<br>第二章 Nginx安装教程</p>
<p>Nginx的安装</p>
<p>模块依赖性Nginx需要依赖下面3个包</p>
<p>gzip 模块需要 zlib 库 ( 点击下载 )<br>rewrite 模块需要 pcre 库 ( 点击下载 )<br>ssl 功能需要 openssl 库 ( 点击下载 )<br>Nginx包下载: <a href="http://nginx.org/en/download.html" target="_blank" rel="external">http://nginx.org/en/download.html</a></p>
<p>依赖包安装顺序依次为:openssl、zlib、pcre, 最后安装Nginx包。</p>
<p>图解教程</p>
<p>第一步： 下载安装所需包</p>
<p>openssl-fips-2.0.2.tar.gz<br>zlib-1.2.7.tar.gz<br>pcre-8.21.tar.gz<br>nginx-1.2.6.tar.gz<br>第二步:依次安装</p>
<p>1.安装openssl-fips-2.0.2.tar.gz</p>
<p>[root@localhost mrms]# tar -zxvf openssl-fips-2.0.2.tar.gz<br>[root@localhost mrms]# cd openssl-fips-2.0.2<br>[root@localhost openssl-fips-2.0.2]# ./config<br>[root@localhost openssl-fips-2.0.2]# make<br>[root@localhost openssl-fips-2.0.2]# make install<br>2.安装zlib-1.2.7.tar.gz</p>
<p>[root@localhost mrms]# tar -zxvf zlib-1.2.7.tar.gz<br>[root@localhost mrms]# cd zlib-1.2.7<br>[root@localhost zlib-1.2.7]# ./configure<br>[root@localhost zlib-1.2.7]# make<br>[root@localhost zlib-1.2.7]# make install<br>3.安装pcre-8.21.tar.gz</p>
<p>[root@localhost mrms]# tar -zxvf pcre-8.21.tar.gz<br>[root@localhost mrms]# cd pcre-8.21<br>[root@localhost pcre-8.21]# ./configure<br>[root@localhost pcre-8.21]# make<br>[root@localhost pcre-8.21]# make install<br>4.安装 nginx-1.2.6.tar.gz</p>
<p>[root@localhost mrms]# tar -zxvf nginx-1.2.6.tar.gz<br>[root@localhost mrms]# cd nginx-1.2.6<br>[root@localhost nginx-1.2.6]# ./configure –with-pcre=../pcre-8.21 –with-zlib=../zlib-1.2.7 –with-openssl=../openssl-fips-2.0.2<br>[root@localhost nginx-1.2.6]# make<br>[root@localhost nginx-1.2.6]# make install<br>至此Nginx的安装完成!</p>
<p>第三步:检测是否安装成功</p>
<p>[root@localhost nginx-1.2.6]# cd  /usr/local/nginx/sbin<br>[root@localhost sbin]# ./nginx -t<br>出现如下所示提示,表示安装成功</p>
<p>安装成功提示</p>
<p>启动nginx<br>[root@localhost sbin]# ./nginx<br>查看端口<br>[root@localhost sbin]# netstat -ntlp<br>结果如下</p>
<p>查看结果<br>第三章 Nginx基本概念</p>
<p>静态HTTP服务器</p>
<p>首先，Nginx是一个HTTP服务器，可以将服务器上的静态文件（如HTML、图片）通过HTTP协议展现给客户端。<br>配置：</p>
<p>server {<br>    listen 80; # 端口号<br>    location / {<br>        root /usr/share/nginx/html; # 静态文件路径<br>    }<br>}<br>反向代理服务器</p>
<p>什么是反向代理？</p>
<p>客户端本来可以直接通过HTTP协议访问某网站应用服务器，如果网站管理员在中间加上一个Nginx，客户端请求Nginx，Nginx请求应用服务器，然后将结果返回给客户端，此时Nginx就是反向代理服务器。</p>
<p>反向代理</p>
<p>反向代理配置：</p>
<p>server {<br>    listen 80;<br>    location / {<br>        proxy_pass <a href="http://192.168.0.112:8080" target="_blank" rel="external">http://192.168.0.112:8080</a>; # 应用服务器HTTP地址<br>    }<br>}<br>既然服务器可以直接HTTP访问，为什么要在中间加上一个反向代理，不是多此一举吗？反向代理有什么作用？继续往下看，下面的负载均衡、虚拟主机，都基于反向代理实现，当然反向代理的功能也不仅仅是这些。</p>
<p>负载均衡</p>
<p>当网站访问量非常大，也摊上事儿了。因为网站越来越慢，一台服务器已经不够用了。于是将相同的应用部署在多台服务器上，将大量用户的请求分配给多台机器处理。同时带来的好处是，其中一台服务器万一挂了，只要还有其他服务器正常运行，就不会影响用户使用。<br>Nginx可以通过反向代理来实现负载均衡。</p>
<p>负载均衡</p>
<p>负载均衡配置：</p>
<p>upstream myapp {<br>    server 192.168.0.111:8080; # 应用服务器1<br>    server 192.168.0.112:8080; # 应用服务器2<br>}<br>server {<br>    listen 80;<br>    location / {<br>        proxy_pass <a href="http://myweb" target="_blank" rel="external">http://myweb</a>;<br>    }<br>}<br>虚拟主机</p>
<p>有的网站访问量大，需要负载均衡。然而并不是所有网站都如此出色，有的网站，由于访问量太小，需要节省成本，将多个网站部署在同一台服务器上。</p>
<p>例如将www.aaa.com和www.bbb.com两个网站部署在同一台服务器上，两个域名解析到同一个IP地址，但是用户通过两个域名却可以打开两个完全不同的网站，互相不影响，就像访问两个服务器一样，所以叫两个虚拟主机。</p>
<p>配置：</p>
<p>server {<br>    listen 80 default_server;<br>    server<em>name </em>;<br>    return 444; # 过滤其他域名的请求，返回444状态码<br>}<br>server {<br>    listen 80;<br>    server_name www.aaa.com; # www.aaa.com域名<br>    location / {<br>        proxy_pass <a href="http://localhost:8080" target="_blank" rel="external">http://localhost:8080</a>; # 对应端口号8080<br>    }<br>}<br>server {<br>    listen 80;<br>    server_name www.bbb.com; # www.bbb.com域名<br>    location / {<br>        proxy_pass <a href="http://localhost:8081" target="_blank" rel="external">http://localhost:8081</a>; # 对应端口号8081<br>    }<br>}<br>在服务器8080和8081分别开了一个应用，客户端通过不同的域名访问，根据server_name可以反向代理到对应的应用服务器。</p>
<p>虚拟主机的原理是通过HTTP请求头中的Host是否匹配server_name来实现的，有兴趣的同学可以研究一下HTTP协议。</p>
<p>另外，server_name配置还可以过滤有人恶意将某些域名指向你的主机服务器。</p>
<p>FastCGI</p>
<p>Nginx本身不支持PHP等语言，但是它可以通过FastCGI来将请求扔给某些语言或框架处理（例如PHP、Python、Perl）。</p>
<p>server {<br>    listen 80;<br>    location ~ .php$ {<br>        include fastcgi_params;<br>        fastcgi_param SCRIPT_FILENAME /PHP文件路径$fastcgi_script_name; # PHP文件路径<br>        fastcgi_pass 127.0.0.1:9000; # PHP-FPM地址和端口号</p>
<pre><code>    # 另一种方式：fastcgi_pass unix:/var/run/php5-fpm.sock;
}
</code></pre><p>}<br>配置中将.php结尾的请求通过FashCGI交给PHP-FPM处理，PHP-FPM是PHP的一个FastCGI管理器。有关FashCGI可以查阅其他资料，本篇不再介绍。</p>
<p>fastcgi_pass和proxy_pass有什么区别？<br>下面一张图带你看明白：</p>
<p>fastcgi_pass和proxy_pass区别<br>第四章 Nginx常用命令</p>
<ol>
<li>启动 Nginx</li>
</ol>
<p>poechant@ubuntu:sudo ./sbin/nginx</p>
<ol>
<li>停止 Nginx</li>
</ol>
<p>poechant@ubuntu:sudo ./sbin/nginx -s stoppoechant@ubuntu:sudo ./sbin/nginx -s quit<br>-s都是采用向 Nginx 发送信号的方式。</p>
<ol>
<li>Nginx 重载配置</li>
</ol>
<p>poechant@ubuntu:sudo ./sbin/nginx -s reload<br>上述是采用向 Nginx 发送信号的方式，或者使用：</p>
<p>poechant@ubuntu:service nginx reload</p>
<ol>
<li>指定配置文件</li>
</ol>
<p>poechant@ubuntu:sudo ./sbin/nginx -c /usr/local/nginx/conf/nginx.conf<br>-c表示configuration，指定配置文件。</p>
<ol>
<li>查看 Nginx 版本</li>
</ol>
<p>有两种可以查看 Nginx 的版本信息的参数。第一种如下：</p>
<p>poechant@ubuntu:/usr/local/nginx$ ./sbin/nginx -v<br>nginx: nginx version: nginx/1.0.0<br>另一种显示的是详细的版本信息：</p>
<p>poechant@ubuntu:/usr/local/nginx$ ./sbin/nginx -V<br>nginx: nginx version: nginx/1.0.0<br>nginx: built by gcc 4.3.3 (Ubuntu 4.3.3-5ubuntu4)<br>nginx: TLS SNI support enabled<br>nginx: configure arguments: –with-http_ssl_module –with-openssl=/home/luming/openssl-1.0.0d/</p>
<ol>
<li>检查配置文件是否正确</li>
</ol>
<p>poechant@ubuntu:/usr/local/nginx$ ./sbin/nginx -t<br>nginx: [alert] could not open error log file: open() “/usr/local/nginx/logs/error.log” failed (13: Permission denied)<br>nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok<br>2012/01/09 16:45:09 [emerg] 23898#0: open() “/usr/local/nginx/logs/nginx.pid” failed (13: Permission denied)<br>nginx: configuration file /usr/local/nginx/conf/nginx.conf test failed<br>如果出现如上的提示信息，表示没有访问错误日志文件和进程，可以sudo（super user do）一下：</p>
<p>poerchant@ubuntu:/usr/local/nginx$ sudo ./sbin/nginx -t<br>nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok<br>nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful<br>如果显示如上，则表示配置文件正确。否则，会有相关提示。</p>
<ol>
<li>显示帮助信息</li>
</ol>
<p>poechant@ubuntu:/user/local/nginx$ ./sbin/nginx -h<br>或者：</p>
<p>poechant@ubuntu:/user/local/nginx$ ./sbin/nginx -?<br>以上这些涵盖了 Nginx 日常维护的所有基本操作，另外还有向 master 进程发送信号的相关命令，我们会在后续看到。</p>
<p>第五章 初探nginx架构</p>
<p>进程模型</p>
<p>众所周知，nginx性能高，而nginx的高性能与其架构是分不开的。那么nginx究竟是怎么样的呢？这一节我们先来初识一下nginx框架吧。</p>
<p>nginx在启动后，在unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。我们也可以手动地关掉后台模式，让nginx在前台运行，并且通过配置让nginx取消master进程，从而可以使nginx以单进程方式运行。</p>
<p>很显然，生产环境下我们肯定不会这么做，所以关闭后台模式，一般是用来调试用的，在后面的章节里面，我们会详细地讲解如何调试nginx。所以，我们可以看到，nginx是以多进程的方式来工作的，当然nginx也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是nginx的默认方式。nginx采用多进程的方式有诸多好处，所以我就主要讲解nginx的多进程模式吧。</p>
<p>刚才讲到，nginx在启动后，会有一个master进程和多个worker进程。</p>
<p>master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。而基本的网络事件，则是放在worker进程中来处理了。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。nginx的进程模型，可以由下图来表示：</p>
<p>nginx进程模型<br>nginx进程操作</p>
<p>在nginx启动后，如果我们要操作nginx，要怎么做呢？</p>
<p>从上文中我们可以看到，master来管理worker进程，所以我们只需要与master进程通信就行了。master进程会接收来自外界发来的信号，再根据信号做不同的事情。所以我们要控制nginx，只需要通过kill向master进程发送信号就行了。</p>
<p>比如kill -HUP pid，则是告诉nginx，从容地重启nginx，我们一般用这个信号来重启nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。</p>
<p>master进程在接收到HUP信号后是怎么做的呢？首先master进程在接到信号后，会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker进程发送信号，告诉他们可以光荣退休了。新的worker在启动后，就开始接收新的请求，而老的worker在收到来自master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。</p>
<p>当然，直接给master进程发送信号，这是比较老的操作方式，nginx在0.8版本之后，引入了一系列命令行参数，来方便我们管理。比如，./nginx -s reload，就是来重启nginx，./nginx -s stop，就是来停止nginx的运行。如何做到的呢？我们还是拿reload来说，我们看到，执行命令时，我们是启动一个新的nginx进程，而新的nginx进程在解析到reload参数后，就知道我们的目的是控制nginx来重新加载配置文件了，它会向master进程发送信号，然后接下来的动作，就和我们直接向master进程发送信号一样了。</p>
<p>事件模型</p>
<p>现在，我们知道了当我们在操作nginx的时候，nginx内部做了些什么事情，那么，worker进程又是如何处理请求的呢？我们前面有提到，worker进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供80端口的http服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？</p>
<p>首先，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。</p>
<p>那么，nginx采用这种进程模型有什么好处呢？当然，好处肯定会很多了。首先，对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快启动新的worker进程。当然，worker进程的异常退出，肯定是程序有bug了，异常退出，会导致当前worker上的所有请求失败，不过不会影响到所有请求，所以降低了风险。当然，好处还有很多，大家可以慢慢体会。</p>
<p>nginx事件处理</p>
<p>上面讲了很多关于nginx的进程模型，接下来，我们来看看nginx是如何处理事件的。</p>
<p>有人可能要问了，nginx采用多worker的方式来处理请求，每个worker里面只有一个主线程，那能够处理的并发数很有限啊，多少个worker就能处理多少个并发，何来高并发呢？非也，这就是nginx的高明之处，nginx采用了异步非阻塞的方式来处理请求，也就是说，nginx是可以同时处理成千上万个请求的。</p>
<p>想想apache的常用工作方式（apache也有异步非阻塞版本，但因其与自带某些模块冲突，所以不常用），每个请求会独占一个工作线程，当并发数上到几千时，就同时有几千的线程在处理请求了。这对操作系统来说，是个不小的挑战，线程带来的内存占用非常大，线程的上下文切换带来的cpu开销很大，自然性能就上不去了，而这些开销完全是没有意义的。</p>
<p>为什么nginx可以采用异步非阻塞的方式来处理呢，或者异步非阻塞到底是怎么回事呢？</p>
<p>我们先回到原点，看看一个请求的完整过程。首先，请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧。</p>
<p>阻塞调用会进入内核等待，cpu就会让出去给别人用了，对单线程的worker来说，显然不合适，当网络事件越多时，大家都在等待呢，cpu空闲下来没人用，cpu利用率自然上不去了，更别谈高并发了。好吧，你说加进程数，这跟apache的线程模型有什么区别，注意，别增加无谓的上下文切换。所以，在nginx里面，最忌讳阻塞的系统调用了。</p>
<p>不要阻塞，那就非阻塞喽。非阻塞就是，事件没有准备好，马上返回EAGAIN，告诉你，事件还没准备好呢，你慌什么，过会再来吧。好吧，你过一会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。虽然不阻塞了，但你得不时地过来检查一下事件的状态，你可以做更多的事情了，但带来的开销也是不小的。</p>
<p>所以，才会有了异步非阻塞的事件处理机制，具体到系统调用就是像select/poll/epoll/kqueue这样的系统调用。它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。</p>
<p>这种机制正好解决了我们上面的两个问题，拿epoll为例(在后面的例子中，我们多以epoll为例子，以代表这一类函数)，当事件没准备好时，放到epoll里面，事件准备好了，我们就去读写，当读写返回EAGAIN时，我们将它再次加入到epoll里面。这样，只要有事件准备好了，我们就去处理它，只有当所有事件都没准备好时，才在epoll里面等着。这样，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。</p>
<p>与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。 我之前有对连接数进行过测试，在24G内存的机器上，处理的并发请求数达到过200万。现在的网络服务器基本都采用这种方式，这也是nginx性能高效的主要原因。</p>
<p>我们之前说过，推荐设置worker的个数为cpu的核数，在这里就很容易理解了，更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，提供了cpu亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。像这种小的优化在nginx中非常常见，同时也说明了nginx作者的苦心孤诣。比如，nginx在做4个字节的字符串比较时，会将4个字符转换成一个int型，再作比较，以减少cpu的指令数等等。</p>
<p>现在，知道了nginx为什么会选择这样的进程模型与事件模型了。对于一个基本的web服务器来说，事件通常有三种类型，网络事件、信号、定时器。从上面的讲解中知道，网络事件通过异步非阻塞可以很好的解决掉。如何处理信号与定时器？</p>
<p>首先，信号的处理。对nginx来说，有一些特定的信号，代表着特定的意义。信号会中断掉程序当前的运行，在改变状态后，继续执行。如果是系统调用，则可能会导致系统调用的失败，需要重入。关于信号的处理，大家可以学习一些专业书籍，这里不多说。对于nginx来说，如果nginx正在等待事件（epoll_wait时），如果程序收到信号，在信号处理函数处理完后，epoll_wait会返回错误，然后程序可再次进入epoll_wait调用。</p>
<p>另外，再来看看定时器。由于epoll_wait等函数在调用的时候是可以设置一个超时时间的，所以nginx借助这个超时时间来实现定时器。nginx里面的定时器事件是放在一颗维护定时器的红黑树里面，每次在进入epoll_wait前，先从该红黑树里面拿到所有定时器事件的最小时间，在计算出epoll_wait的超时时间后进入epoll_wait。</p>
<p>所以，当没有事件产生，也没有中断信号时，epoll_wait会超时，也就是说，定时器事件到了。这时，nginx会检查所有的超时事件，将他们的状态设置为超时，然后再去处理网络事件。由此可以看出，当我们写nginx代码时，在处理网络事件的回调函数时，通常做的第一个事情就是判断超时，然后再去处理网络事件。<br>我们可以用一段伪代码来总结一下nginx的事件处理模型：</p>
<p>while (true)<br> {<br>for t in run_tasks: t.handler();<br>update_time(&amp;now);<br>timeout = ETERNITY;<br>for t in wait_tasks: /<em> sorted already </em>/ if (t.time &lt;= now)<br>{<br>t.timeout_handler();<br> } else<br> {<br>timeout = t.time - now; break;<br>} nevents = poll_function(events, timeout);<br>for i in nevents: task t;<br>if (events[i].type == READ)<br>{<br> t.handler = read_handler;<br>} else<br>{<br> /<em> events[i].type == WRITE </em>/ t.handler = write_handler;<br>} run_tasks_add(t);}<br>好，本节我们讲了进程模型，事件模型，包括网络事件，信号，定时器事件。</p>
<p>nginx基础概念</p>
<p>connection</p>
<p>在nginx中connection就是对tcp连接的封装，其中包括连接的socket，读事件，写事件。利用nginx封装的connection，我们可以很方便的使用nginx来处理与连接相关的事情，比如，建立连接，发送与接受数据等。而nginx中的http请求的处理就是建立在connection之上的，所以nginx不仅可以作为一个web服务器，也可以作为邮件服务器。当然，利用nginx提供的connection，我们可以与任何后端服务打交道。</p>
<p>结合一个tcp连接的生命周期，我们看看nginx是如何处理一个连接的。首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，然后在nginx的master进程里面，先初始化好这个监控的socket(创建socket，设置addrreuse等选项，绑定到指定的ip地址端口，再listen)，然后再fork出多个子进程出来，然后子进程会竞争accept新的连接。此时，客户端就可以向nginx发起连接了。当客户端与服务端通过三次握手建立好一个连接后，nginx的某一个子进程会accept成功，得到这个建立好的连接的socket，然后创建nginx对连接的封装，即ngx_connection_t结构体。接着，设置读写事件处理函数并添加读写事件来与客户端进行数据的交换。最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了。</p>
<p>当然，nginx也是可以作为客户端来请求其它server的数据的（如upstream模块），此时，与其它server创建的连接，也封装在ngx_connection_t中。作为客户端，nginx先获取一个ngx_connection_t结构体，然后创建socket，并设置socket的属性（ 比如非阻塞）。然后再通过添加读写事件，调用connect/read/write来调用连接，最后关掉连接，并释放ngx_connection_t。</p>
<p>在nginx中，每个进程会有一个连接数的最大上限，这个上限与系统对fd的限制不一样。在操作系统中，通过ulimit -n，我们可以得到一个进程所能够打开的fd的最大数，即nofile，因为每个socket连接会占用掉一个fd，所以这也会限制我们进程的最大连接数，当然也会直接影响到我们程序所能支持的最大并发数，当fd用完后，再创建socket时，就会失败。</p>
<p>nginx通过设置worker_connectons来设置每个进程支持的最大连接数。如果该值大于nofile，那么实际的最大连接数是nofile，nginx会有警告。nginx在实现时，是通过一个连接池来管理的，每个worker进程都有一个独立的连接池，连接池的大小是worker_connections。这里的连接池里面保存的其实不是真实的连接，它只是一个worker_connections大小的一个ngx_connection_t结构的数组。并且，nginx会通过一个链表free_connections来保存所有的空闲ngx_connection_t，每次获取一个连接时，就从空闲连接链表中获取一个，用完后，再放回空闲连接链表里面。</p>
<p>在这里，很多人会误解worker_connections这个参数的意思，认为这个值就是nginx所能建立连接的最大值。其实不然，这个值是表示每个worker进程所能建立连接的最大值，所以，一个nginx能建立的最大连接数，应该是worker_connections worker_processes。当然，这里说的是最大连接数，对于HTTP请求本地资源来说，能够支持的最大并发数量是worker_connections worker_processes，而如果是HTTP作为反向代理来说，最大并发数量应该是worker_connections * worker_processes/2。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。</p>
<p>那么，我们前面有说过一个客户端连接过来后，多个空闲的进程，会竞争这个连接，很容易看到，这种竞争会导致不公平，如果某个进程得到accept的机会比较多，它的空闲连接很快就用完了，如果不提前做一些控制，当accept到一个新的tcp连接后，因为无法得到空闲连接，而且无法将此连接转交给其它进程，最终会导致此tcp连接得不到处理，就中止掉了。很显然，这是不公平的，有的进程有空余连接，却没有处理机会，有的进程因为没有空余连接，却人为地丢弃连接。</p>
<p>那么，如何解决这个问题呢？首先，nginx的处理得先打开accept_mutex选项，此时，只有获得了accept_mutex的进程才会去添加accept事件，也就是说，nginx会控制进程是否添加accept事件。nginx使用一个叫ngx_accept_disabled的变量来控制是否去竞争accept_mutex锁。</p>
<p>在第一段代码中，计算ngx_accept_disabled的值，这个值是nginx单进程的所有连接总数的八分之一，减去剩下的空闲连接数量，得到的这个ngx_accept_disabled有一个规律，当剩余连接数小于总连接数的八分之一时，其值才大于0，而且剩余的连接数越小，这个值越大。</p>
<p>再看第二段代码，当ngx_accept_disabled大于0时，不会去尝试获取accept_mutex锁，并且将ngx_accept_disabled减1，于是，每次执行到此处时，都会去减1，直到小于0。不去获取accept_mutex锁，就是等于让出获取连接的机会，很显然可以看出，当空余连接越少时，ngx_accept_disable越大，于是让出的机会就越多，这样其它进程获取锁的机会也就越大。不去accept，自己的连接就控制下来了，其它进程的连接池就会得到利用，这样，nginx就控制了多进程间连接的平衡了。</p>
<p>ngx_accept_disabled = ngx_cycle-&gt;connection_n / 8</p>
<pre><code>- ngx_cycle-&gt;free_connection_n;
</code></pre><p>if (ngx_accept_disabled &gt; 0) {<br>    ngx_accept_disabled–;</p>
<p>} else {<br>    if (ngx_trylock_accept_mutex(cycle) == NGX_ERROR) {<br>        return;<br>    }</p>
<pre><code>if (ngx_accept_mutex_held) {
    flags |= NGX_POST_EVENTS;

} else {
    if (timer == NGX_TIMER_INFINITE
            || timer &gt; ngx_accept_mutex_delay)
    {
        timer = ngx_accept_mutex_delay;
    }
}
</code></pre><p>}<br>好了，连接就先介绍到这，本章的目的是介绍基本概念，知道在nginx中连接是个什么东西就行了，而且连接是属于比较高级的用法，在后面的模块开发高级篇会有专门的章节来讲解连接与事件的实现及使用。</p>
<p>request</p>
<p>这节我们讲request，在nginx中我们指的是http请求，具体到nginx中的数据结构是ngx_http_request_t。ngx_http_request_t是对一个http请求的封装。 我们知道，一个http请求，包含请求行、请求头、请求体、响应行、响应头、响应体。</p>
<p>http请求是典型的请求-响应类型的的网络协议，而http是文件协议，所以我们在分析请求行与请求头，以及输出响应行与响应头，往往是一行一行的进行处理。如果我们自己来写一个http服务器，通常在一个连接建立好后，客户端会发送请求过来。然后我们读取一行数据，分析出请求行中包含的method、uri、http_version信息。然后再一行一行处理请求头，并根据请求method与请求头的信息来决定是否有请求体以及请求体的长度，然后再去读取请求体。得到请求后，我们处理请求产生需要输出的数据，然后再生成响应行，响应头以及响应体。在将响应发送给客户端之后，一个完整的请求就处理完了。</p>
<p>当然这是最简单的webserver的处理方式，其实nginx也是这样做的，只是有一些小小的区别，比如，当请求头读取完成后，就开始进行请求的处理了。nginx通过ngx_http_request_t来保存解析请求与输出响应相关的数据。</p>
<p>那接下来，简要讲讲nginx是如何处理一个完整的请求的。对于nginx来说，一个请求是从ngx_http_init_request开始的，在这个函数中，会设置读事件为ngx_http_process_request_line，也就是说，接下来的网络事件，会由ngx_http_process_request_line来执行。</p>
<p>从ngx_http_process_request_line的函数名，我们可以看到，这就是来处理请求行的，正好与之前讲的，处理请求的第一件事就是处理请求行是一致的。通过ngx_http_read_request_header来读取请求数据。然后调用ngx_http_parse_request_line函数来解析请求行。nginx为提高效率，采用状态机来解析请求行，而且在进行method的比较时，没有直接使用字符串比较，而是将四个字符转换成一个整型，然后一次比较以减少cpu的指令数，这个前面有说过。</p>
<p>很多人可能很清楚一个请求行包含请求的方法，uri，版本，却不知道其实在请求行中，也是可以包含有host的。比如一个请求GET <a href="http://www.taobao.com/uri" target="_blank" rel="external">http://www.taobao.com/uri</a> HTTP/1.0这样一个请求行也是合法的，而且host是www.taobao.com，这个时候，nginx会忽略请求头中的host域，而以请求行中的这个为准来查找虚拟主机。另外，对于对于http0.9版来说，是不支持请求头的，所以这里也是要特别的处理。所以，在后面解析请求头时，协议版本都是1.0或1.1。整个请求行解析到的参数，会保存到ngx_http_request_t结构当中。</p>
<p>在解析完请求行后，nginx会设置读事件的handler为ngx_http_process_request_headers，然后后续的请求就在ngx_http_process_request_headers中进行读取与解析。ngx_http_process_request_headers函数用来读取请求头，跟请求行一样，还是调用ngx_http_read_request_header来读取请求头，调用ngx_http_parse_header_line来解析一行请求头，解析到的请求头会保存到ngx_http_request_t的域headers_in中，headers_in是一个链表结构，保存所有的请求头。而HTTP中有些请求是需要特别处理的，这些请求头与请求处理函数存放在一个映射表里面，即ngx_http_headers_in，在初始化时，会生成一个hash表，当每解析到一个请求头后，就会先在这个hash表中查找，如果有找到，则调用相应的处理函数来处理这个请求头。比如:Host头的处理函数是ngx_http_process_host。</p>
<p>当nginx解析到两个回车换行符时，就表示请求头的结束，此时就会调用ngx_http_process_request来处理请求了。ngx_http_process_request会设置当前的连接的读写事件处理函数为ngx_http_request_handler，然后再调用ngx_http_handler来真正开始处理一个完整的http请求。</p>
<p>这里可能比较奇怪，读写事件处理函数都是ngx_http_request_handler，其实在这个函数中，会根据当前事件是读事件还是写事件，分别调用ngx_http_request_t中的read_event_handler或者是write_event_handler。由于此时，我们的请求头已经读取完成了，之前有说过，nginx的做法是先不读取请求body，所以这里面我们设置read_event_handler为ngx_http_block_reading，即不读取数据了。</p>
<p>刚才说到，真正开始处理数据，是在ngx_http_handler这个函数里面，这个函数会设置write_event_handler为ngx_http_core_run_phases，并执行ngx_http_core_run_phases函数。ngx_http_core_run_phases这个函数将执行多阶段请求处理，nginx将一个http请求的处理分为多个阶段，那么这个函数就是执行这些阶段来产生数据。因为ngx_http_core_run_phases最后会产生数据，所以我们就很容易理解，为什么设置写事件的处理函数为ngx_http_core_run_phases了。</p>
<p>在这里，我简要说明了一下函数的调用逻辑，我们需要明白最终是调用ngx_http_core_run_phases来处理请求，产生的响应头会放在ngx_http_request_t的headers_out中，这一部分内容，我会放在请求处理流程里面去讲。nginx的各种阶段会对请求进行处理，最后会调用filter来过滤数据，对数据进行加工，如truncked传输、gzip压缩等。</p>
<p>这里的filter包括header filter与body filter，即对响应头或响应体进行处理。filter是一个链表结构，分别有header filter与body filter，先执行header filter中的所有filter，然后再执行body filter中的所有filter。在header filter中的最后一个filter，即ngx_http_header_filter，这个filter将会遍历所有的响应头，最后需要输出的响应头在一个连续的内存，然后调用ngx_http_write_filter进行输出。ngx_http_write_filter是body filter中的最后一个，所以nginx首先的body信息，在经过一系列的body filter之后，最后也会调用ngx_http_write_filter来进行输出(有图来说明)。</p>
<p>这里要注意的是，nginx会将整个请求头都放在一个buffer里面，这个buffer的大小通过配置项client_header_buffer_size来设置，如果用户的请求头太大，这个buffer装不下，那nginx就会重新分配一个新的更大的buffer来装请求头，这个大buffer可以通过large_client_header_buffers来设置，这个large_buffer这一组buffer，比如配置4 8k，就是表示有四个8k大小的buffer可以用。</p>
<p>注意，为了保存请求行或请求头的完整性，一个完整的请求行或请求头，需要放在一个连续的内存里面，所以，一个完整的请求行或请求头，只会保存在一个buffer里面。这样，如果请求行大于一个buffer的大小，就会返回414错误，如果一个请求头大小大于一个buffer大小，就会返回400错误。在了解了这些参数的值，以及nginx实际的做法之后，在应用场景，我们就需要根据实际的需求来调整这些参数，来优化我们的程序了。</p>
<p>处理流程图：</p>
<p>请求处理流程<br>以上这些，就是nginx中一个http请求的生命周期了。我们再看看与请求相关的一些概念吧。</p>
<p>keepalive</p>
<p>当然，在nginx中，对于http1.0与http1.1也是支持长连接的。</p>
<p>什么是长连接呢？我们知道，http请求是基于TCP协议之上的，那么，当客户端在发起请求前，需要先与服务端建立TCP连接，而每一次的TCP连接是需要三次握手来确定的，如果客户端与服务端之间网络差一点，这三次交互消费的时间会比较多，而且三次交互也会带来网络流量。当然，当连接断开后，也会有四次的交互，当然对用户体验来说就不重要了。而http请求是请求应答式的，如果我们能知道每个请求头与响应体的长度，那么我们是可以在一个连接上面执行多个请求的，这就是所谓的长连接，但前提条件是我们先得确定请求头与响应体的长度。</p>
<p>对于请求来说，如果当前请求需要有body，如POST请求，那么nginx就需要客户端在请求头中指定content-length来表明body的大小，否则返回400错误。也就是说，请求体的长度是确定的，那么响应体的长度呢？先来看看http协议中关于响应body长度的确定：</p>
<p>对于http1.0协议来说，如果响应头中有content-length头，则以content-length的长度就可以知道body的长度了，客户端在接收body时，就可以依照这个长度来接收数据，接收完后，就表示这个请求完成了。而如果没有content-length头，则客户端会一直接收数据，直到服务端主动断开连接，才表示body接收完了。<br>而对于http1.1协议来说，如果响应头中的Transfer-encoding为chunked传输，则表示body是流式输出，body会被分成多个块，每块的开始会标识出当前块的长度，此时，body不需要通过长度来指定。如果是非chunked传输，而且有content-length，则按照content-length来接收数据。否则，如果是非chunked，并且没有content-length，则客户端接收数据，直到服务端主动断开连接。<br>从上面，我们可以看到，除了http1.0不带content-length以及http1.1非chunked不带content-length外，body的长度是可知的。此时，当服务端在输出完body之后，会可以考虑使用长连接。能否使用长连接，也是有条件限制的。如果客户端的请求头中的connection为close，则表示客户端需要关掉长连接，如果为keep-alive，则客户端需要打开长连接，如果客户端的请求中没有connection这个头，那么根据协议，如果是http1.0，则默认为close，如果是http1.1，则默认为keep-alive。如果结果为keepalive，那么，nginx在输出完响应体后，会设置当前连接的keepalive属性，然后等待客户端下一次请求。</p>
<p>当然，nginx不可能一直等待下去，如果客户端一直不发数据过来，岂不是一直占用这个连接？所以当nginx设置了keepalive等待下一次的请求时，同时也会设置一个最大等待时间，这个时间是通过选项keepalive_timeout来配置的，如果配置为0，则表示关掉keepalive，此时，http版本无论是1.1还是1.0，客户端的connection不管是close还是keepalive，都会强制为close。</p>
<p>如果服务端最后的决定是keepalive打开，那么在响应的http头里面，也会包含有connection头域，其值是”Keep-Alive”，否则就是”Close”。如果connection值为close，那么在nginx响应完数据后，会主动关掉连接。所以，对于请求量比较大的nginx来说，关掉keepalive最后会产生比较多的time-wait状态的socket。一般来说，当客户端的一次访问，需要多次访问同一个server时，打开keepalive的优势非常大，比如图片服务器，通常一个网页会包含很多个图片。打开keepalive也会大量减少time-wait的数量。</p>
<p>pipe</p>
<p>在http1.1中，引入了一种新的特性，即pipeline。</p>
<p>那么什么是pipeline呢？pipeline其实就是流水线作业，它可以看作为keepalive的一种升华，因为pipeline也是基于长连接的，目的就是利用一个连接做多次请求。如果客户端要提交多个请求，对于keepalive来说，那么第二个请求，必须要等到第一个请求的响应接收完全后，才能发起，这和TCP的停止等待协议是一样的，得到两个响应的时间至少为2RTT。而对pipeline来说，客户端不必等到第一个请求处理完后，就可以马上发起第二个请求。得到两个响应的时间可能能够达到1RTT。nginx是直接支持pipeline的，但是，nginx对pipeline中的多个请求的处理却不是并行的，依然是一个请求接一个请求的处理，只是在处理第一个请求的时候，客户端就可以发起第二个请求。</p>
<p>这样，nginx利用pipeline减少了处理完一个请求后，等待第二个请求的请求头数据的时间。其实nginx的做法很简单，前面说到，nginx在读取数据时，会将读取的数据放到一个buffer里面，所以，如果nginx在处理完前一个请求后，如果发现buffer里面还有数据，就认为剩下的数据是下一个请求的开始，然后就接下来处理下一个请求，否则就设置keepalive。</p>
<p>lingering_close</p>
<p>lingering_close，字面意思就是延迟关闭，也就是说，当nginx要关闭连接时，并非立即关闭连接，而是先关闭tcp连接的写，再等待一段时间后再关掉连接的读。</p>
<p>为什么要这样呢？我们先来看看这样一个场景。nginx在接收客户端的请求时，可能由于客户端或服务端出错了，要立即响应错误信息给客户端，而nginx在响应错误信息后，大分部情况下是需要关闭当前连接。nginx执行完write()系统调用把错误信息发送给客户端，write()系统调用返回成功并不表示数据已经发送到客户端，有可能还在tcp连接的write buffer里。接着如果直接执行close()系统调用关闭tcp连接，内核会首先检查tcp的read buffer里有没有客户端发送过来的数据留在内核态没有被用户态进程读取，如果有则发送给客户端RST报文来关闭tcp连接丢弃write buffer里的数据，如果没有则等待write buffer里的数据发送完毕，然后再经过正常的4次分手报文断开连接。</p>
<p>所以,当在某些场景下出现tcp write buffer里的数据在write()系统调用之后到close()系统调用执行之前没有发送完毕，且tcp read buffer里面还有数据没有读，close()系统调用会导致客户端收到RST报文且不会拿到服务端发送过来的错误信息数据。那客户端肯定会想，这服务器好霸道，动不动就reset我的连接，连个错误信息都没有。</p>
<p>在上面这个场景中，我们可以看到，关键点是服务端给客户端发送了RST包，导致自己发送的数据在客户端忽略掉了。所以，解决问题的重点是，让服务端别发RST包。再想想，我们发送RST是因为我们关掉了连接，关掉连接是因为我们不想再处理此连接了，也不会有任何数据产生了。对于全双工的TCP连接来说，我们只需要关掉写就行了，读可以继续进行，我们只需要丢掉读到的任何数据就行了，这样的话，当我们关掉连接后，客户端再发过来的数据，就不会再收到RST了。当然最终我们还是需要关掉这个读端的，所以我们会设置一个超时时间，在这个时间过后，就关掉读，客户端再发送数据来就不管了，作为服务端我会认为，都这么长时间了，发给你的错误信息也应该读到了，再慢就不关我事了，要怪就怪你RP不好了。</p>
<p>当然，正常的客户端，在读取到数据后，会关掉连接，此时服务端就会在超时时间内关掉读端。这些正是lingering_close所做的事情。协议栈提供 SO_LINGER 这个选项，它的一种配置情况就是来处理lingering_close的情况的，不过nginx是自己实现的lingering_close。lingering_close存在的意义就是来读取剩下的客户端发来的数据，所以nginx会有一个读超时时间，通过lingering_timeout选项来设置，如果在lingering_timeout时间内还没有收到数据，则直接关掉连接。</p>
<p>nginx还支持设置一个总的读取时间，通过lingering_time来设置，这个时间也就是nginx在关闭写之后，保留socket的时间，客户端需要在这个时间内发送完所有的数据，否则nginx在这个时间过后，会直接关掉连接。当然，nginx是支持配置是否打开lingering_close选项的，通过lingering_close选项来配置。 那么，我们在实际应用中，是否应该打开lingering_close呢？这个就没有固定的推荐值了，如Maxim Dounin所说，lingering_close的主要作用是保持更好的客户端兼容性，但是却需要消耗更多的额外资源（比如连接会一直占着）。</p>
<p>这节，我们介绍了nginx中，连接与请求的基本概念，下节，我们讲基本的数据结构。</p>
<p>第六章 基本数据结构（一）</p>
<p>nginx的作者为追求极致的高效，自己实现了很多颇具特色的nginx风格的数据结构以及公共函数。比如，nginx提供了带长度的字符串，根据编译器选项优化过的字符串拷贝函数ngx_copy等。所以，在我们写nginx模块时，应该尽量调用nginx提供的api，尽管有些api只是对glibc的宏定义。本节，我们介绍string、list、buffer、chain等一系列最基本的数据结构及相关api的使用技巧以及注意事项。</p>
<p>ngx_str_t</p>
<p>在nginx源码目录的src/core下面的ngx_string.h|c里面，包含了字符串的封装以及字符串相关操作的api。nginx提供了一个带长度的字符串结构ngx_str_t，它的原型如下：</p>
<p>typedef struct { size_t len; u_char *data;} ngx_str_t;<br>在结构体当中，data指向字符串数据的第一个字符，字符串的结束用长度来表示，而不是由’\0’来表示结束。所以，在写nginx代码时，处理字符串的方法跟我们平时使用有很大的不一样，但要时刻记住，字符串不以’\0’结束，尽量使用nginx提供的字符串操作的api来操作字符串。</p>
<p>那么，nginx这样做有什么好处呢？首先，通过长度来表示字符串长度，减少计算字符串长度的次数。其次，nginx可以重复引用一段字符串内存，data可以指向任意内存，长度表示结束，而不用去copy一份自己的字符串(因为如果要以’\0’结束，而不能更改原字符串，所以势必要copy一段字符串)。我们在ngx_http_request_t结构体的成员中，可以找到很多字符串引用一段内存的例子，比如request_line、uri、args等等，这些字符串的data部分，都是指向在接收数据时创建buffer所指向的内存中，uri，args就没有必要copy一份出来。这样的话，减少了很多不必要的内存分配与拷贝。</p>
<p>正是基于此特性，在nginx中，必须谨慎的去修改一个字符串。在修改字符串时需要认真的去考虑：是否可以修改该字符串；字符串修改后，是否会对其它的引用造成影响。在后面介绍ngx_unescape_uri函数的时候，就会看到这一点。但是，使用nginx的字符串会产生一些问题，glibc提供的很多系统api函数大多是通过’\0’来表示字符串的结束，所以我们在调用系统api时，就不能直接传入str-&gt;data了。此时，通常的做法是创建一段str-&gt;len + 1大小的内存，然后copy字符串，最后一个字节置为’\0’。比较hack的做法是，将字符串最后一个字符的后一个字符backup一个，然后设置为’\0’，在做完调用后，再由backup改回来，但前提条件是，你得确定这个字符是可以修改的，而且是有内存分配，不会越界，但一般不建议这么做。 接下来，看看nginx提供的操作字符串相关的api。</p>
<p>define ngx_string(str) { sizeof(str) - 1, (u_char *) str }<br>ngx_string(str)是一个宏，它通过一个以’\0’结尾的普通字符串str构造一个nginx的字符串，鉴于其中采用sizeof操作符计算字符串长度，因此参数必须是一个常量字符串。</p>
<p>define ngx_null_string { 0, NULL }<br>定义变量时，使用ngx_null_string初始化字符串为空字符串，符串的长度为0，data为NULL。</p>
<p>define ngx_str_set(str, text) \ (str)-&gt;len = sizeof(text) - 1; (str)-&gt;data = (u_char *) text<br>ngx_str_set用于设置字符串str为text，由于使用sizeof计算长度，故text必须为常量字符串。</p>
<p>define ngx_str_null(str) (str)-&gt;len = 0; (str)-&gt;data = NULL<br>ngx_str_null用于设置字符串str为空串，长度为0，data为NULL。<br>上面这四个函数，使用时一定要小心，ngx_string与ngx_null_string是“{，}”格式的，故只能用于赋值时初始化，如：</p>
<p>ngx_str_t str = ngx_string(“hello world”);<br>ngx_str_t str1 = ngx_null_string;<br>如果向下面这样使用，就会有问题，这里涉及到c语言中对结构体变量赋值操作的语法规则，在此不做介绍。</p>
<p>ngx_str_t str, str1;<br>str = ngx_string(“hello world”); // 编译出错<br>str1 = ngx_null_string; // 编译出错<br>这种情况，可以调用ngx_str_set与ngx_str_null这两个函数来做:</p>
<p>ngx_str_t str, str1;<br>ngx_str_set(&amp;str, “hello world”);<br>ngx_str_null(&amp;str1);<br>按照C99标准，您也可以这么做：</p>
<p>ngx_str_t str, str1;<br>str = (ngx_str_t) ngx_string(“hello world”);s<br>tr1 = (ngx_str_t) ngx_null_string;<br>另外要注意的是，ngx_string与ngx_str_set在调用时，传进去的字符串一定是常量字符串，否则会得到意想不到的错误(因为ngx_str_set内部使用了sizeof()，如果传入的是u_char*，那么计算的是这个指针的长度，而不是字符串的长度)。如：</p>
<p>ngx_str_t str;<br>u_char *a = “hello world”;<br>ngx_str_set(&amp;str, a); // 问题产生<br>此外，值得注意的是，由于ngx_str_set与ngx_str_null实际上是两行语句，故在if/for/while等语句中单独使用需要用花括号括起来，例如：</p>
<p>ngx_str_t str;<br>if (cond) ngx_str_set(&amp;str, “true”); // 问题产生<br>else ngx_str_set(&amp;str, “false”); // 问题产生<br>void ngx_strlow(u_char <em>dst, u_char </em>src, size_t n);<br>将src的前n个字符转换成小写存放在dst字符串当中，调用者需要保证dst指向的空间大于等于n，且指向的空间必须可写。操作不会对原字符串产生变动。如要更改原字符串，可以：</p>
<p>ngx_strlow(str-&gt;data, str-&gt;data, str-&gt;len);</p>
<p>ngx_strncmp(s1, s2, n)</p>
<p>区分大小写的字符串比较，只比较前n个字符。</p>
<p>ngx_strcmp(s1, s2)<br>区分大小写的不带长度的字符串比较。</p>
<p>ngx_int_t ngx_strcasecmp(u_char <em>s1, u_char </em>s2);<br>不区分大小写的不带长度的字符串比较。</p>
<p>ngx_int_t ngx_strncasecmp(u_char <em>s1, u_char </em>s2, size_t n);<br>不区分大小写的带长度的字符串比较，只比较前n个字符。</p>
<p>u_char <em> ngx_cdecl ngx_sprintf(u_char </em>buf, const char <em>fmt, …);<br>u_char </em> ngx_cdecl ngx_snprintf(u_char <em>buf, size_t max, const char </em>fmt, …);<br>u_char <em> ngx_cdecl ngx_slprintf(u_char </em>buf, u_char <em>last, const char </em>fmt, …);<br>上面这三个函数用于字符串格式化，ngx_snprintf的第二个参数max指明buf的空间大小，ngx_slprintf则通过last来指明buf空间的大小。推荐使用第二个或第三个函数来格式化字符串，ngx_sprintf函数还是比较危险的，容易产生缓冲区溢出漏洞。在这一系列函数中，nginx在兼容glibc中格式化字符串的形式之外，还添加了一些方便格式化nginx类型的一些转义字符，比如%V用于格式化ngx_str_t结构。在nginx源文件的ngx_string.c中有说明：</p>
<p>/*</p>
<ul>
<li>supported formats: <ul>
<li>%[0][width][x][X]O off_t</li>
<li>%[0][width]T time_t </li>
<li>%[0][width][u][x|X]z ssize_t/size_t </li>
<li>%[0][width][u][x|X]d int/u_int </li>
<li>%[0][width][u][x|X]l long </li>
<li>%[0][width|m][u][x|X]i ngx_int_t/ngx_uint_t </li>
<li>%[0][width][u][x|X]D int32_t/uint32_t </li>
<li>%[0][width][u][x|X]L int64_t/uint64_t </li>
<li>%[0][width|m][u][x|X]A ngx_atomic_int_t/ngx_atomic_uint_t </li>
<li>%[0][width][.width]f double, max valid number fits to %18.15f </li>
<li>%P ngx_pid_t </li>
<li>%M ngx_msec_t </li>
<li>%r rlim_t </li>
<li>%p void * </li>
<li>%V ngx_str_t * </li>
<li>%v ngx_variable_value_t * </li>
<li>%s null-terminated string </li>
<li>%*s length and string </li>
<li>%Z ‘\0’ </li>
<li>%N ‘\n’ </li>
<li>%c char </li>
<li>%% % * </li>
<li>reserved: </li>
<li>%t ptrdiff_t </li>
<li>%S null-terminated wchar string </li>
<li>%C wchar */<br>这里特别要提醒的是，我们最常用于格式化ngx_str_t结构，其对应的转义符是%V，传给函数的一定要是指针类型，否则程序就会coredump掉。这也是我们最容易犯的错。比如：</li>
</ul>
</li>
</ul>
<p>ngx_str_t str = ngx_string(“hello world”);<br>char buffer[1024];ngx_snprintf(buffer, 1024, “%V”, &amp;str); // 注意，str取地址<br>void ngx_encode_base64(ngx_str_t <em>dst, ngx_str_t </em>src);<br>ngx_int_t ngx_decode_base64(ngx_str_t <em>dst, ngx_str_t </em>src);<br>这两个函数用于对str进行base64编码与解码，调用前，需要保证dst中有足够的空间来存放结果，如果不知道具体大小，可先调用ngx_base64_encoded_length与ngx_base64_decoded_length来预估最大占用空间。</p>
<p>uintptr_t ngx_escape_uri(u_char <em>dst, u_char </em>src, size_t size,<br> ngx_uint_t type);<br>对src进行编码，根据type来按不同的方式进行编码，如果dst为NULL，则返回需要转义的字符的数量，由此可得到需要的空间大小。type的类型可以是：</p>
<p>#define NGX_ESCAPE_URI          0</p>
<p>#define NGX_ESCAPE_ARGS         1</p>
<p>#define NGX_ESCAPE_HTML         2</p>
<p>#define NGX_ESCAPE_REFRESH      3</p>
<p>#define NGX_ESCAPE_MEMCACHED    4</p>
<p>#define NGX_ESCAPE_MAIL_AUTH    5<br>void ngx_unescape_uri(u_char <strong>dst, u_char </strong>src, size_t size, ngx_uint_t type);<br>对src进行反编码，type可以是0、NGX_UNESCAPE_URI、NGX_UNESCAPE_REDIRECT这三个值。如果是0，则表示src中的所有字符都要进行转码。如果是NGX_UNESCAPE_URI与NGX_UNESCAPE_REDIRECT，则遇到’?’后就结束了，后面的字符就不管了。而NGX_UNESCAPE_URI与NGX_UNESCAPE_REDIRECT之间的区别是NGX_UNESCAPE_URI对于遇到的需要转码的字符，都会转码，而NGX_UNESCAPE_REDIRECT则只会对非可见字符进行转码。</p>
<p>uintptr_t ngx_escape_html(u_char <em>dst, u_char </em>src, size_t size);<br>对html标签进行编码。<br>当然，我这里只介绍了一些常用的api的使用，大家可以先熟悉一下，在实际使用过程中，遇到不明白的，最快最直接的方法就是去看源码，看api的实现或看nginx自身调用api的地方是怎么做的，代码就是最好的文档。</p>
<p>ngx_pool_t</p>
<p>ngx_pool_t是一个非常重要的数据结构，在很多重要的场合都有使用，很多重要的数据结构也都在使用它。那么它究竟是一个什么东西呢？简单的说，它提供了一种机制，帮助管理一系列的资源（如内存，文件等），使得对这些资源的使用和释放统一进行，免除了使用过程中考虑到对各种各样资源的什么时候释放，是否遗漏了释放的担心。</p>
<p>例如对于内存的管理，如果我们需要使用内存，那么总是从一个ngx_pool_t的对象中获取内存，在最终的某个时刻，我们销毁这个ngx_pool_t对象，所有这些内存都被释放了。这样我们就不必要对对这些内存进行malloc和free的操作，不用担心是否某块被malloc出来的内存没有被释放。因为当ngx_pool_t对象被销毁的时候，所有从这个对象中分配出来的内存都会被统一释放掉。</p>
<p>再比如我们要使用一系列的文件，但是我们打开以后，最终需要都关闭，那么我们就把这些文件统一登记到一个ngx_pool_t对象中，当这个ngx_pool_t对象被销毁的时候，所有这些文件都将会被关闭。</p>
<p>从上面举的两个例子中我们可以看出，使用ngx_pool_t这个数据结构的时候，所有的资源的释放都在这个对象被销毁的时刻，统一进行了释放，那么就会带来一个问题，就是这些资源的生存周期（或者说被占用的时间）是跟ngx_pool_t的生存周期基本一致（ngx_pool_t也提供了少量操作可以提前释放资源）。从最高效的角度来说，这并不是最好的。比如，我们需要依次使用A，B，C三个资源，且使用完B的时候，A就不会再被使用了，使用C的时候A和B都不会被使用到。如果不使用ngx_pool_t来管理这三个资源，那我们可能从系统里面申请A，使用A，然后在释放A。接着申请B，使用B，再释放B。最后申请C，使用C，然后释放C。但是当我们使用一个ngx_pool_t对象来管理这三个资源的时候，A，B和C的释放是在最后一起发生的，也就是在使用完C以后。诚然，这在客观上增加了程序在一段时间的资源使用量。但是这也减轻了程序员分别管理三个资源的生命周期的工作。这也就是有所得，必有所失的道理。实际上是一个取舍的问题，要看在具体的情况下，你更在乎的是哪个。</p>
<p>可以看一下在nginx里面一个典型的使用ngx_pool_t的场景，对于nginx处理的每个http request, nginx会生成一个ngx_pool_t对象与这个http request关联，所有处理过程中需要申请的资源都从这个ngx_pool_t对象中获取，当这个http request处理完成以后，所有在处理过程中申请的资源，都将随着这个关联的ngx_pool_t对象的销毁而释放。</p>
<p>ngx_pool_t相关结构及操作被定义在文件src/core/ngx_palloc.h|c中。</p>
<p>typedef struct ngx_pool_s ngx_pool_t;<br>struct ngx_pool_s { ngx_pool_data_t d;<br> size_t max; ngx_pool_t <em>current;<br>ngx_chain_t </em>chain;<br> ngx_pool_large_t <em>large;<br>ngx_pool_cleanup_t </em>cleanup;<br> ngx_log_t *log;};<br>从ngx_pool_t的一般使用者的角度来说，可不用关注ngx_pool_t结构中各字段作用。所以这里也不会进行详细的解释，当然在说明某些操作函数的使用的时候，如有必要，会进行说明。<br>下面我们来分别解释下ngx_pool_t的相关操作。</p>
<p>ngx_pool_t <em>ngx_create_pool(size_t size, ngx_log_t </em>log);<br>创建一个初始节点大小为size的pool，log为后续在该pool上进行操作时输出日志的对象。 需要说明的是size的选择，size的大小必须小于等于NGX_MAX_ALLOC_FROM_POOL，且必须大于sizeof(ngx_pool_t)。</p>
<p>选择大于NGX_MAX_ALLOC_FROM_POOL的值会造成浪费，因为大于该限制的空间不会被用到（只是说在第一个由ngx_pool_t对象管理的内存块上的内存，后续的分配如果第一个内存块上的空闲部分已用完，会再分配的）。<br>选择小于sizeof(ngx_pool_t)的值会造成程序崩溃。由于初始大小的内存块中要用一部分来存储ngx_pool_t这个信息本身。<br>当一个ngx_pool_t对象被创建以后，该对象的max字段被赋值为size-sizeof(ngx_pool_t)和NGX_MAX_ALLOC_FROM_POOL这两者中比较小的。后续的从这个pool中分配的内存块，在第一块内存使用完成以后，如果要继续分配的话，就需要继续从操作系统申请内存。当内存的大小小于等于max字段的时候，则分配新的内存块，链接在d这个字段（实际上是d.next字段）管理的一条链表上。当要分配的内存块是比max大的，那么从系统中申请的内存是被挂接在large字段管理的一条链表上。我们暂且把这个称之为大块内存链和小块内存链。</p>
<p>void <em>ngx_palloc(ngx_pool_t </em>pool, size_t size);<br>从这个pool中分配一块为size大小的内存。注意，此函数分配的内存的起始地址按照NGX_ALIGNMENT进行了对齐。对齐操作会提高系统处理的速度，但会造成少量内存的浪费。</p>
<p>void <em>ngx_pnalloc(ngx_pool_t </em>pool, size_t size);<br>从这个pool中分配一块为size大小的内存。但是此函数分配的内存并没有像上面的函数那样进行过对齐。</p>
<p>void <em>ngx_pcalloc(ngx_pool_t </em>pool, size_t size);<br>该函数也是分配size大小的内存，并且对分配的内存块进行了清零。内部实际上是转调用ngx_palloc实现的。</p>
<p>void <em>ngx_pmemalign(ngx_pool_t </em>pool, size_t size, size_t alignment);<br>按照指定对齐大小alignment来申请一块大小为size的内存。此处获取的内存不管大小都将被置于大内存块链中管理。</p>
<p>ngx_int_t ngx_pfree(ngx_pool_t <em>pool, void </em>p);<br>对于被置于大块内存链，也就是被large字段管理的一列内存中的某块进行释放。该函数的实现是顺序遍历large管理的大块内存链表。所以效率比较低下。如果在这个链表中找到了这块内存，则释放，并返回NGX_OK。否则返回NGX_DECLINED。</p>
<p>由于这个操作效率比较低下，除非必要，也就是说这块内存非常大，确应及时释放，否则一般不需要调用。反正内存在这个pool被销毁的时候，总归会都释放掉的嘛！</p>
<p>ngx_pool_cleanup_t <em>ngx_pool_cleanup_add(ngx_pool_t </em>p, size_t size);<br>ngx_pool_t中的cleanup字段管理着一个特殊的链表，该链表的每一项都记录着一个特殊的需要释放的资源。对于这个链表中每个节点所包含的资源如何去释放，是自说明的。这也就提供了非常大的灵活性。意味着，ngx_pool_t不仅仅可以管理内存，通过这个机制，也可以管理任何需要释放的资源，例如，关闭文件，或者删除文件等等。下面我们看一下这个链表每个节点的类型:</p>
<p>typedef struct ngx_pool_cleanup_s ngx_pool_cleanup_t;<br>typedef void (<em>ngx_pool_cleanup_pt)(void </em>data);<br>struct ngx_pool_cleanup_s { ngx_pool_cleanup_pt handler;<br>void <em>data; ngx_pool_cleanup_t </em>next;};<br>data:<br>指明了该节点所对应的资源。</p>
<p>handler:<br>是一个函数指针，指向一个可以释放data所对应资源的函数。该函数只有一个参数，就是data。</p>
<p>next:<br>指向该链表中下一个元素。</p>
<p>看到这里，ngx_pool_cleanup_add这个函数的用法，我相信大家都应该有一些明白了。但是这个参数size是起什么作用的呢？这个 size就是要存储这个data字段所指向的资源的大小，该函数会为data分配size大小的空间。</p>
<p>比如我们需要最后删除一个文件。那我们在调用这个函数的时候，把size指定为存储文件名的字符串的大小，然后调用这个函数给cleanup链表中增加一项。该函数会返回新添加的这个节点。我们然后把这个节点中的data字段拷贝为文件名。把hander字段赋值为一个删除文件的函数（当然该函数的原型要按照void (ngx_pool_cleanup_pt)(void data)）。</p>
<p>void ngx_destroy_pool(ngx_pool_t *pool);<br>该函数就是释放pool中持有的所有内存，以及依次调用cleanup字段所管理的链表中每个元素的handler字段所指向的函数，来释放掉所有该pool管理的资源。并且把pool指向的ngx_pool_t也释放掉了，完全不可用了。</p>
<p>void ngx_reset_pool(ngx_pool_t *pool);<br>该函数释放pool中所有大块内存链表上的内存，小块内存链上的内存块都修改为可用。但是不会去处理cleanup链表上的项目。</p>
<p>ngx_array_t</p>
<p>ngx_array_t是nginx内部使用的数组结构。nginx的数组结构在存储上与大家认知的C语言内置的数组有相似性，比如实际上存储数据的区域也是一大块连续的内存。但是数组除了存储数据的内存以外还包含一些元信息来描述相关的一些信息。下面我们从数组的定义上来详细的了解一下。ngx_array_t的定义位于src/core/ngx_array.c|h里面。</p>
<p>typedef struct ngx_array_s ngx_array_t;<br>struct ngx_array_s { void <em>elts;<br>ngx_uint_t nelts;<br>size_t size;<br>ngx_uint_t nalloc;<br>ngx_pool_t </em>pool;};<br>elts:<br>指向实际的数据存储区域。</p>
<p>nelts:<br>数组实际元素个数。</p>
<p>size:<br>数组单个元素的大小，单位是字节。</p>
<p>nalloc:<br>数组的容量。表示该数组在不引发扩容的前提下，可以最多存储的元素的个数。当nelts增长到达nalloc 时，如果再往此数组中存储元素，则会引发数组的扩容。数组的容量将会扩展到原有容量的2倍大小。实际上是分配新的一块内存，新的一块内存的大小是原有内存大小的2倍。原有的数据会被拷贝到新的一块内存中。</p>
<p>pool:<br>该数组用来分配内存的内存池。</p>
<p>下面介绍ngx_array_t相关操作函数。</p>
<p>ngx_array_t <em>ngx_array_create(ngx_pool_t </em>p, ngx_uint_t n, size_t size);<br>创建一个新的数组对象，并返回这个对象。</p>
<p>p:<br>数组分配内存使用的内存池；</p>
<p>n:<br>数组的初始容量大小，即在不扩容的情况下最多可以容纳的元素个数。</p>
<p>size:<br>单个元素的大小，单位是字节。</p>
<p>void ngx_array_destroy(ngx_array_t *a);<br>销毁该数组对象，并释放其分配的内存回内存池。</p>
<p>void <em>ngx_array_push(ngx_array_t </em>a);<br>在数组a上新追加一个元素，并返回指向新元素的指针。需要把返回的指针使用类型转换，转换为具体的类型，然后再给新元素本身或者是各字段（如果数组的元素是复杂类型）赋值。</p>
<p>void <em>ngx_array_push_n(ngx_array_t </em>a, ngx_uint_t n);<br>在数组a上追加n个元素，并返回指向这些追加元素的首个元素的位置的指针。</p>
<p>static ngx_inline ngx_int_t ngx_array_init(ngx_array_t <em>array, ngx_pool_t </em>pool, ngx_uint_t n, size_t size);<br>如果一个数组对象是被分配在堆上的，那么当调用ngx_array_destroy销毁以后，如果想再次使用，就可以调用此函数。<br>如果一个数组对象是被分配在栈上的，那么就需要调用此函数，进行初始化的工作以后，才可以使用。</p>
<p>注意事项: 由于使用ngx_palloc分配内存，数组在扩容时，旧的内存不会被释放，会造成内存的浪费。因此，最好能提前规划好数组的容量，在创建或者初始化的时候一次搞定，避免多次扩容，造成内存浪费。</p>
<p>ngx_hash_t</p>
<p>ngx_hash_t是nginx自己的hash表的实现。定义和实现位于src/core/ngx_hash.h|c中。ngx_hash_t的实现也与数据结构教科书上所描述的hash表的实现是大同小异。对于常用的解决冲突的方法有线性探测，二次探测和开链法等。ngx_hash_t使用的是最常用的一种，也就是开链法，这也是STL中的hash表使用的方法。</p>
<p>但是ngx_hash_t的实现又有其几个显著的特点:</p>
<p>ngx_hash_t不像其他的hash表的实现，可以插入删除元素，它只能一次初始化，就构建起整个hash表以后，既不能再删除，也不能在插入元素了。</p>
<p>ngx_hash_t的开链并不是真的开了一个链表，实际上是开了一段连续的存储空间，几乎可以看做是一个数组。这是因为ngx_hash_t在初始化的时候，会经历一次预计算的过程，提前把每个桶里面会有多少元素放进去给计算出来，这样就提前知道每个桶的大小了。那么就不需要使用链表，一段连续的存储空间就足够了。这也从一定程度上节省了内存的使用。</p>
<p>从上面的描述，我们可以看出来，这个值越大，越造成内存的浪费。就两步，首先是初始化，然后就可以在里面进行查找了。下面我们详细来看一下。</p>
<p>ngx_hash_t的初始化。</p>
<p>ngx_int_t ngx_hash_init(ngx_hash_init_t <em>hinit, ngx_hash_key_t </em>names,ngx_uint_t nelts);<br>首先我们来看一下初始化函数。该函数的第一个参数hinit是初始化的一些参数的一个集合。 names是初始化一个ngx_hash_t所需要的所有key的一个数组。而nelts就是key的个数。下面先看一下ngx_hash_init_t类型，该类型提供了初始化一个hash表所需要的一些基本信息。</p>
<p>typedef struct {<br>ngx_hash_t <em>hash;<br>ngx_hash_key_pt key;<br>ngx_uint_t max_size;<br>ngx_uint_t bucket_size;<br> char </em>name;<br>ngx_pool_t <em>pool;<br>ngx_pool_t </em>temp_pool;<br>} ngx_hash_init_t;<br>hash:<br>该字段如果为NULL，那么调用完初始化函数后，该字段指向新创建出来的hash表。如果该字段不为NULL，那么在初始的时候，所有的数据被插入了这个字段所指的hash表中。</p>
<p>key:<br>指向从字符串生成hash值的hash函数。nginx的源代码中提供了默认的实现函数ngx_hash_key_lc。</p>
<p>max_size:<br>hash表中的桶的个数。该字段越大，元素存储时冲突的可能性越小，每个桶中存储的元素会更少，则查询起来的速度更快。当然，这个值越大，越造成内存的浪费也越大，(实际上也浪费不了多少)。</p>
<p>bucket_size:<br>每个桶的最大限制大小，单位是字节。如果在初始化一个hash表的时候，发现某个桶里面无法存的下所有属于该桶的元素，则hash表初始化失败。</p>
<p>name:<br>该hash表的名字。</p>
<p>pool:<br>该hash表分配内存使用的pool。</p>
<p>temp_pool:<br>该hash表使用的临时pool，在初始化完成以后，该pool可以被释放和销毁掉。</p>
<p>下面来看一下存储hash表key的数组的结构。</p>
<p>typedef struct {<br>ngx_str_t key;<br> ngx_uint_t key_hash;<br>void *value;<br>} ngx_hash_key_t;<br>key和value的含义显而易见，就不用解释了。key_hash是对key使用hash函数计算出来的值。 对这两个结构分析完成以后，我想大家应该都已经明白这个函数应该是如何使用了吧。该函数成功初始化一个hash表以后，返回NGX_OK，否则返回NGX_ERROR。</p>
<p>void <em>ngx_hash_find(ngx_hash_t </em>hash, ngx_uint_t key, u_char *name, size_t len);<br>在hash里面查找key对应的value。实际上这里的key是对真正的key（也就是name）计算出的hash值。len是name的长度。<br>如果查找成功，则返回指向value的指针，否则返回NULL。</p>
<p>ngx_hash_wildcard_t</p>
<p>nginx为了处理带有通配符的域名的匹配问题，实现了ngx_hash_wildcard_t这样的hash表。他可以支持两种类型的带有通配符的域名。一种是通配符在前的，例如：“.abc.com”，也可以省略掉星号，直接写成”.abc.com”。这样的key，可以匹配www.abc.com，qqq.www.abc.com之类的。另外一种是通配符在末尾的，例如：“mail.xxx.”，请特别注意通配符在末尾的不像位于开始的通配符可以被省略掉。这样的通配符，可以匹配mail.xxx.com、mail.xxx.com.cn、mail.xxx.net之类的域名。</p>
<p>有一点必须说明，就是一个ngx_hash_wildcard_t类型的hash表只能包含通配符在前的key或者是通配符在后的key。不能同时包含两种类型的通配符的key。ngx_hash_wildcard_t类型变量的构建是通过函数ngx_hash_wildcard_init完成的，而查询是通过函数ngx_hash_find_wc_head或者ngx_hash_find_wc_tail来做的。ngx_hash_find_wc_head是查询包含通配符在前的key的hash表的，而ngx_hash_find_wc_tail是查询包含通配符在后的key的hash表的。</p>
<p>下面详细说明这几个函数的用法。</p>
<p>ngx_int_t ngx_hash_wildcard_init(ngx_hash_init_t <em>hinit, ngx_hash_key_t </em>names,<br>ngx_uint_t nelts);<br>该函数迎来构建一个可以包含通配符key的hash表。</p>
<p>hinit:<br>构造一个通配符hash表的一些参数的一个集合。关于该参数对应的类型的说明，请参见ngx_hash_t类型中ngx_hash_init函数的说明。</p>
<p>names:<br>构造此hash表的所有的通配符key的数组。特别要注意的是这里的key已经都是被预处理过的。例如：“.abc.com”或者“.abc.com”被预处理完成以后，变成了“com.abc.”。而“mail.xxx.”则被预处理为“mail.xxx.”。为什么会被处理这样？这里不得不简单地描述一下通配符hash表的实现原理。当构造此类型的hash表的时候，实际上是构造了一个hash表的一个“链表”，是通过hash表中的key“链接”起来的。比如：对于“.abc.com”将会构造出2个hash表，第一个hash表中有一个key为com的表项，该表项的value包含有指向第二个hash表的指针，而第二个hash表中有一个表项abc，该表项的value包含有指向.abc.com对应的value的指针。那么查询的时候，比如查询www.abc.com的时候，先查com，通过查com可以找到第二级的hash表，在第二级hash表中，再查找abc，依次类推，直到在某一级的hash表中查到的表项对应的value对应一个真正的值而非一个指向下一级hash表的指针的时候，查询过程结束。</p>
<p>这里有一点需要特别注意的，就是names数组中元素的value值低两位bit必须为0（有特殊用途）。如果不满足这个条件，这个hash表查询不出正确结果。</p>
<p>nelts:<br>names数组元素的个数。</p>
<p>该函数执行成功返回NGX_OK，否则NGX_ERROR。</p>
<p>void <em>ngx_hash_find_wc_head(ngx_hash_wildcard_t </em>hwc, u_char *name, size_t len);<br>该函数查询包含通配符在前的key的hash表的。</p>
<p>hwc:<br>hash表对象的指针。</p>
<p>name:<br>需要查询的域名，例如: www.abc.com。</p>
<p>len:<br>name的长度。</p>
<p>该函数返回匹配的通配符对应value。如果没有查到，返回NULL。</p>
<p>void <em>ngx_hash_find_wc_tail(ngx_hash_wildcard_t </em>hwc, u_char *name, size_t len);<br>该函数查询包含通配符在末尾的key的hash表的。 参数及返回值请参加上个函数的说明。</p>
<p>ngx_hash_combined_t</p>
<p>组合类型hash表，该hash表的定义如下：</p>
<p>typedef struct {<br>ngx_hash_t hash;<br>ngx_hash_wildcard_t <em>wc_head;<br>ngx_hash_wildcard_t </em>wc_tail;<br>} ngx_hash_combined_t;<br>从其定义显见，该类型实际上包含了三个hash表，一个普通hash表，一个包含前向通配符的hash表和一个包含后向通配符的hash表。</p>
<p>nginx提供该类型的作用，在于提供一个方便的容器包含三个类型的hash表，当有包含通配符的和不包含通配符的一组key构建hash表以后，以一种方便的方式来查询，你不需要再考虑一个key到底是应该到哪个类型的hash表里去查了。</p>
<p>构造这样一组合hash表的时候，首先定义一个该类型的变量，再分别构造其包含的三个子hash表即可。<br>对于该类型hash表的查询，nginx提供了一个方便的函数ngx_hash_find_combined。</p>
<p>void <em>ngx_hash_find_combined(ngx_hash_combined_t </em>hash, ngx_uint_t key,<br>u_char *name, size_t len);<br>该函数在此组合hash表中，依次查询其三个子hash表，看是否匹配，一旦找到，立即返回查找结果，也就是说如果有多个可能匹配，则只返回第一个匹配的结果。</p>
<p>hash:<br>此组合hash表对象。</p>
<p>key:<br>根据name计算出的hash值。</p>
<p>name:<br>key的具体内容。</p>
<p>len:<br>name的长度。</p>
<p>返回查询的结果，未查到则返回NULL。</p>
<p>第七章 基本数据结构（二）</p>
<p>ngx_hash_keys_arrays_t</p>
<p>大家看到在构建一个ngx_hash_wildcard_t的时候，需要对通配符的哪些key进行预处理。这个处理起来比较麻烦。而当有一组key，这些里面既有无通配符的key，也有包含通配符的key的时候。我们就需要构建三个hash表，一个包含普通的key的hash表，一个包含前向通配符的hash表，一个包含后向通配符的hash表（或者也可以把这三个hash表组合成一个ngx_hash_combined_t）。在这种情况下，为了让大家方便的构造这些hash表，nginx提供给了此辅助类型。</p>
<p>该类型以及相关的操作函数也定义在src/core/ngx_hash.h|c里。我们先来看一下该类型的定义。</p>
<p>typedef struct {<br> ngx_uint_t hsize;<br>ngx_pool_t <em>pool;<br>ngx_pool_t </em>temp_pool;<br>ngx_array_t keys;<br>ngx_array_t <em>keys_hash;<br>ngx_array_t dns_wc_head;<br>ngx_array_t </em>dns_wc_head_hash;<br>ngx_array_t dns_wc_tail;<br>ngx_array_t *dns_wc_tail_hash;<br>} ngx_hash_keys_arrays_t;<br>hsize:<br>将要构建的hash表的桶的个数。对于使用这个结构中包含的信息构建的三种类型的hash表都会使用此参数。</p>
<p>pool:<br>构建这些hash表使用的pool。</p>
<p>temp_pool:<br>在构建这个类型以及最终的三个hash表过程中可能用到临时pool。该temp_pool可以在构建完成以后，被销毁掉。这里只是存放临时的一些内存消耗。</p>
<p>keys:<br>存放所有非通配符key的数组。</p>
<p>keys_hash:<br>这是个二维数组，第一个维度代表的是bucket的编号，那么keys_hash[i]中存放的是所有的key算出来的hash值对hsize取模以后的值为i的key。假设有3个key,分别是key1,key2和key3假设hash值算出来以后对hsize取模的值都是i，那么这三个key的值就顺序存放在keys_hash[i][0],keys_hash[i][1], keys_hash[i][2]。该值在调用的过程中用来保存和检测是否有冲突的key值，也就是是否有重复。</p>
<p>dns_wc_head:<br>放前向通配符key被处理完成以后的值。比如：“*.abc.com” 被处理完成以后，变成 “com.abc.” 被存放在此数组中。</p>
<p>dns_wc_tail:<br>存放后向通配符key被处理完成以后的值。比如：“mail.xxx.*” 被处理完成以后，变成 “mail.xxx.” 被存放在此数组中。</p>
<p>dns_wc_head_hash:<br>该值在调用的过程中用来保存和检测是否有冲突的前向通配符的key值，也就是是否有重复。</p>
<p>dns_wc_tail_hash:<br>该值在调用的过程中用来保存和检测是否有冲突的后向通配符的key值，也就是是否有重复。</p>
<p>在定义一个这个类型的变量，并对字段pool和temp_pool赋值以后，就可以调用函数ngx_hash_add_key把所有的key加入到这个结构中了，该函数会自动实现普通key，带前向通配符的key和带后向通配符的key的分类和检查，并将这个些值存放到对应的字段中去， 然后就可以通过检查这个结构体中的keys、dns_wc_head、dns_wc_tail三个数组是否为空，来决定是否构建普通hash表，前向通配符hash表和后向通配符hash表了（在构建这三个类型的hash表的时候，可以分别使用keys、dns_wc_head、dns_wc_tail三个数组）。</p>
<p>构建出这三个hash表以后，可以组合在一个ngx_hash_combined_t对象中，使用ngx_hash_find_combined进行查找。或者是仍然保持三个独立的变量对应这三个hash表，自己决定何时以及在哪个hash表中进行查询。</p>
<p>ngx_int_t ngx_hash_keys_array_init(ngx_hash_keys_arrays_t *ha, ngx_uint_t type);<br>初始化这个结构，主要是对这个结构中的ngx_array_t类型的字段进行初始化，成功返回NGX_OK。</p>
<p>ha:<br>该结构的对象指针。</p>
<p>type:<br>该字段有2个值可选择，即NGX_HASH_SMALL和NGX_HASH_LARGE。用来指明将要建立的hash表的类型，如果是NGX_HASH_SMALL，则有比较小的桶的个数和数组元素大小。NGX_HASH_LARGE则相反。</p>
<p>ngx_int_t ngx_hash_add_key(ngx_hash_keys_arrays_t <em>ha, ngx_str_t </em>key,<br>void *value, ngx_uint_t flags);<br>一般是循环调用这个函数，把一组键值对加入到这个结构体中。返回NGX_OK是加入成功。返回NGX_BUSY意味着key值重复。</p>
<p>ha:<br>该结构的对象指针。</p>
<p>key:<br>参数名自解释了。</p>
<p>value:<br>参数名自解释了。</p>
<p>flags:<br>有两个标志位可以设置，NGX_HASH_WILDCARD_KEY和NGX_HASH_READONLY_KEY。同时要设置的使用逻辑与操作符就可以了。NGX_HASH_READONLY_KEY被设置的时候，在计算hash值的时候，key的值不会被转成小写字符，否则会。NGX_HASH_WILDCARD_KEY被设置的时候，说明key里面可能含有通配符，会进行相应的处理。如果两个标志位都不设置，传0。</p>
<p>有关于这个数据结构的使用，可以参考src/http/ngx_http.c中的ngx_http_server_names函数。</p>
<p>ngx_chain_t</p>
<p>nginx的filter模块在处理从别的filter模块或者是handler模块传递过来的数据（实际上就是需要发送给客户端的http response）。这个传递过来的数据是以一个链表的形式(ngx_chain_t)。而且数据可能被分多次传递过来。也就是多次调用filter的处理函数，以不同的ngx_chain_t。</p>
<p>该结构被定义在src/core/ngx_buf.h|c。下面我们来看一下ngx_chain_t的定义。</p>
<p>typedef struct ngx_chain_s ngx_chain_t;<br>struct ngx_chain_s { ngx_buf_t <em>buf;<br>ngx_chain_t </em>next;};<br>就2个字段，next指向这个链表的下个节点。buf指向实际的数据。所以在这个链表上追加节点也是非常容易，只要把末尾元素的next指针指向新的节点，把新节点的next赋值为NULL即可。</p>
<p>ngx_chain_t <em>ngx_alloc_chain_link(ngx_pool_t </em>pool);<br>该函数创建一个ngx_chain_t的对象，并返回指向对象的指针，失败返回NULL。</p>
<p>#define ngx_free_chain(pool, cl)<br> \ cl-&gt;next = pool-&gt;chain;<br>\pool-&gt;chain = cl<br>该宏释放一个ngx_chain_t类型的对象。如果要释放整个chain，则迭代此链表，对每个节点使用此宏即可。<br>注意: 对ngx_chaint_t类型的释放，并不是真的释放了内存，而仅仅是把这个对象挂在了这个pool对象的一个叫做chain的字段对应的chain上，以供下次从这个pool上分配ngx_chain_t类型对象的时候，快速的从这个pool-&gt;chain上取下链首元素就返回了，当然，如果这个链是空的，才会真的在这个pool上使用ngx_palloc函数进行分配。</p>
<p>ngx_buf_t</p>
<p>这个ngx_buf_t就是这个ngx_chain_t链表的每个节点的实际数据。该结构实际上是一种抽象的数据结构，它代表某种具体的数据。这个数据可能是指向内存中的某个缓冲区，也可能指向一个文件的某一部分，也可能是一些纯元数据（元数据的作用在于指示这个链表的读取者对读取的数据进行不同的处理）。</p>
<p>该数据结构位于src/core/ngx_buf.h|c文件中。我们来看一下它的定义。</p>
<p>struct ngx_buf_s {<br>u_char <em>pos;<br>u_char </em>last;<br>off_t file_pos;<br>off_t file_last;<br>u_char <em>start; /</em> start of buffer <em>/<br>u_char </em>end; /<em> end of buffer </em>/<br>ngx_buf_tag_t tag;<br>ngx_file_t <em>file;<br>ngx_buf_t </em>shadow;</p>
<p> /<em> the buf’s content could be changed </em>/ </p>
<p>unsigned temporary:1; </p>
<p>/* </p>
<ul>
<li>the buf’s content is in a memory cache or in a read only memory </li>
<li>and must not be changed<br>*/ </li>
</ul>
<p>unsigned memory:1;<br> /<em> the buf’s content is mmap()ed and must not be changed </em>/<br>unsigned mmap:1;<br>unsigned recycled:1;<br>unsigned in_file:1;<br>unsigned flush:1;<br>unsigned sync:1;<br>unsigned last_buf:1;<br>unsigned last_in_chain:1;<br>unsigned last_shadow:1;<br>unsigned temp_file:1; </p>
<p>/<em> STUB </em>/ int num;};<br>pos:<br>当buf所指向的数据在内存里的时候，pos指向的是这段数据开始的位置。</p>
<p>last:<br>当buf所指向的数据在内存里的时候，last指向的是这段数据结束的位置。</p>
<p>file_pos:<br>当buf所指向的数据是在文件里的时候，file_pos指向的是这段数据的开始位置在文件中的偏移量。</p>
<p>file_last:<br>当buf所指向的数据是在文件里的时候，file_last指向的是这段数据的结束位置在文件中的偏移量。</p>
<p>start:<br>当buf所指向的数据在内存里的时候，这一整块内存包含的内容可能被包含在多个buf中(比如在某段数据中间插入了其他的数据，这一块数据就需要被拆分开)。那么这些buf中的start和end都指向这一块内存的开始地址和结束地址。而pos和last指向本buf所实际包含的数据的开始和结尾。</p>
<p>end:<br>解释参见start。</p>
<p>tag:<br>实际上是一个void*类型的指针，使用者可以关联任意的对象上去，只要对使用者有意义。</p>
<p>file:<br>当buf所包含的内容在文件中时，file字段指向对应的文件对象。</p>
<p>shadow:<br>当这个buf完整copy了另外一个buf的所有字段的时候，那么这两个buf指向的实际上是同一块内存，或者是同一个文件的同一部分，此时这两个buf的shadow字段都是指向对方的。那么对于这样的两个buf，在释放的时候，就需要使用者特别小心，具体是由哪里释放，要提前考虑好，如果造成资源的多次释放，可能会造成程序崩溃！</p>
<p>temporary:<br>为1时表示该buf所包含的内容是在一个用户创建的内存块中，并且可以被在filter处理的过程中进行变更，而不会造成问题。</p>
<p>memory:<br>为1时表示该buf所包含的内容是在内存中，但是这些内容却不能被进行处理的filter进行变更。</p>
<p>mmap:<br>为1时表示该buf所包含的内容是在内存中, 是通过mmap使用内存映射从文件中映射到内存中的，这些内容却不能被进行处理的filter进行变更。</p>
<p>recycled:<br>可以回收的。也就是这个buf是可以被释放的。这个字段通常是配合shadow字段一起使用的，对于使用ngx_create_temp_buf 函数创建的buf，并且是另外一个buf的shadow，那么可以使用这个字段来标示这个buf是可以被释放的。</p>
<p>in_file:<br>为1时表示该buf所包含的内容是在文件中。</p>
<p>flush:<br>遇到有flush字段被设置为1的的buf的chain，则该chain的数据即便不是最后结束的数据（last_buf被设置，标志所有要输出的内容都完了），也会进行输出，不会受postpone_output配置的限制，但是会受到发送速率等其他条件的限制。</p>
<p>sync:</p>
<p>last_buf:<br>数据被以多个chain传递给了过滤器，此字段为1表明这是最后一个buf。</p>
<p>last_in_chain:<br>在当前的chain里面，此buf是最后一个。特别要注意的是last_in_chain的buf不一定是last_buf，但是last_buf的buf一定是last_in_chain的。这是因为数据会被以多个chain传递给某个filter模块。</p>
<p>last_shadow:<br>在创建一个buf的shadow的时候，通常将新创建的一个buf的last_shadow置为1。</p>
<p>temp_file:<br>由于受到内存使用的限制，有时候一些buf的内容需要被写到磁盘上的临时文件中去，那么这时，就设置此标志 。</p>
<p>对于此对象的创建，可以直接在某个ngx_pool_t上分配，然后根据需要，给对应的字段赋值。也可以使用定义好的2个宏：</p>
<p>#define ngx_alloc_buf(pool) ngx_palloc(pool, sizeof(ngx_buf_t))</p>
<p>#define ngx_calloc_buf(pool) ngx_pcalloc(pool, sizeof(ngx_buf_t))<br>这两个宏使用类似函数，也是不说自明的。<br>对于创建temporary字段为1的buf（就是其内容可以被后续的filter模块进行修改），可以直接使用函数ngx_create_temp_buf进行创建。</p>
<p>ngx_buf_t <em>ngx_create_temp_buf(ngx_pool_t </em>pool, size_t size);<br>该函数创建一个ngx_but_t类型的对象，并返回指向这个对象的指针，创建失败返回NULL。<br>对于创建的这个对象，它的start和end指向新分配内存开始和结束的地方。pos和last都指向这块新分配内存的开始处，这样，后续的操作可以在这块新分配的内存上存入数据。</p>
<p>pool:<br>分配该buf和buf使用的内存所使用的pool。</p>
<p>size:<br>该buf使用的内存的大小。</p>
<p>为了配合对ngx_buf_t的使用，nginx定义了以下的宏方便操作。</p>
<p>#define ngx_buf_in_memory(b) (b-&gt;temporary || b-&gt;memory || b-&gt;mmap)<br>返回这个buf里面的内容是否在内存里。</p>
<p>#define ngx_buf_in_memory_only(b) (ngx_buf_in_memory(b) &amp;&amp; !b-&gt;in_file)<br>返回这个buf里面的内容是否仅仅在内存里，并且没有在文件里。</p>
<p>#define ngx_buf_special(b) \<br>((b-&gt;flush || b-&gt;last_buf || b-&gt;sync) \<br>&amp;&amp; !ngx_buf_in_memory(b) &amp;&amp; !b-&gt;in_file)<br>返回该buf是否是一个特殊的buf，只含有特殊的标志和没有包含真正的数据。</p>
<p>#define ngx_buf_sync_only(b) \<br>(b-&gt;sync \<br>&amp;&amp; !ngx_buf_in_memory(b) &amp;&amp; !b-&gt;in_file &amp;&amp; !b-&gt;flush &amp;&amp; !b-&gt;last_buf)<br>返回该buf是否是一个只包含sync标志而不包含真正数据的特殊buf。</p>
<p>#define ngx_buf_size(b) \<br>(ngx_buf_in_memory(b) ? (off_t) (b-&gt;last - b-&gt;pos): \<br>(b-&gt;file_last - b-&gt;file_pos))<br>返回该buf所含数据的大小，不管这个数据是在文件里还是在内存里。</p>
<p>ngx_list_t</p>
<p>ngx_list_t顾名思义，看起来好像是一个list的数据结构。这样的说法，算对也不算对。因为它符合list类型数据结构的一些特点，比如可以添加元素，实现自增长，不会像数组类型的数据结构，受到初始设定的数组容量的限制，并且它跟我们常见的list型数据结构也是一样的，内部实现使用了一个链表。</p>
<p>那么它跟我们常见的链表实现的list有什么不同呢？不同点就在于它的节点，它的节点不像我们常见的list的节点，只能存放一个元素，ngx_list_t的节点实际上是一个固定大小的数组。</p>
<p>在初始化的时候，我们需要设定元素需要占用的空间大小，每个节点数组的容量大小。在添加元素到这个list里面的时候，会在最尾部的节点里的数组上添加元素，如果这个节点的数组存满了，就再增加一个新的节点到这个list里面去。</p>
<p>好了，看到这里，大家应该基本上明白这个list结构了吧？还不明白也没有关系，下面我们来具体看一下它的定义，这些定义和相关的操作函数定义在src/core/ngx_list.h|c文件中。</p>
<p>typedef struct {<br>ngx_list_part_t <em>last;<br>ngx_list_part_t part;<br>size_t size;<br>ngx_uint_t nalloc;<br>ngx_pool_t </em>pool;<br>} ngx_list_t;<br>last:<br>指向该链表的最后一个节点。</p>
<p>part:<br>该链表的首个存放具体元素的节点。</p>
<p>size:<br>链表中存放的具体元素所需内存大小。</p>
<p>nalloc:<br>每个节点所含的固定大小的数组的容量。</p>
<p>pool:<br>该list使用的分配内存的pool。</p>
<p>好，我们在看一下每个节点的定义。</p>
<p>typedef struct ngx_list_part_s ngx_list_part_t;<br>struct ngx_list_part_s {<br>void <em>elts;<br>ngx_uint_t nelts;<br>ngx_list_part_t </em>next;<br>};<br>elts:<br>节点中存放具体元素的内存的开始地址。</p>
<p>nelts:<br>节点中已有元素个数。这个值是不能大于链表头节点ngx_list_t类型中的nalloc字段的。</p>
<p>next:<br>指向下一个节点。</p>
<p>我们来看一下提供的一个操作的函数。</p>
<p>ngx_list_t <em>ngx_list_create(ngx_pool_t </em>pool, ngx_uint_t n, size_t size);<br>该函数创建一个ngx_list_t类型的对象,并对该list的第一个节点分配存放元素的内存空间。</p>
<p>pool:<br>分配内存使用的pool。</p>
<p>n:<br>每个节点固定长度的数组的长度。</p>
<p>size:<br>存放的具体元素的个数。</p>
<p>返回值:<br>成功返回指向创建的ngx_list_t对象的指针，失败返回NULL。</p>
<p>void <em>ngx_list_push(ngx_list_t </em>list);<br>该函数在给定的list的尾部追加一个元素，并返回指向新元素存放空间的指针。如果追加失败，则返回NULL。</p>
<p>static ngx_inline ngx_int_t<br>ngx_list_init(ngx_list_t <em>list, ngx_pool_t </em>pool, ngx_uint_t n, size_t size);<br>该函数是用于ngx_list_t类型的对象已经存在，但是其第一个节点存放元素的内存空间还未分配的情况下，可以调用此函数来给这个list的首节点来分配存放元素的内存空间。</p>
<p>那么什么时候会出现已经有了ngx_list_t类型的对象，而其首节点存放元素的内存尚未分配的情况呢？那就是这个ngx_list_t类型的变量并不是通过调用ngx_list_create函数创建的。例如：如果某个结构体的一个成员变量是ngx_list_t类型的，那么当这个结构体类型的对象被创建出来的时候，这个成员变量也被创建出来了，但是它的首节点的存放元素的内存并未被分配。</p>
<p>总之，如果这个ngx_list_t类型的变量，如果不是你通过调用函数ngx_list_create创建的，那么就必须调用此函数去初始化，否则，你往这个list里追加元素就可能引发不可预知的行为，亦或程序会崩溃!</p>
<p>ngx_queue_t</p>
<p>ngx_queue_t是nginx中的双向链表，在nginx源码目录src/core下面的ngx_queue.h|c里面。它的原型如下：</p>
<p>typedef struct ngx_queue_s ngx_queue_t;</p>
<p>struct ngx_queue_s {<br>ngx_queue_t <em>prev;<br>ngx_queue_t </em>next;<br>};<br>不同于教科书中将链表节点的数据成员声明在链表节点的结构体中，ngx_queue_t只是声明了前向和后向指针。在使用的时候，我们首先需要定义一个哨兵节点(对于后续具体存放数据的节点，我们称之为数据节点)，比如：</p>
<p>ngx_queue_t free;<br>接下来需要进行初始化，通过宏ngx_queue_init()来实现：</p>
<p>ngx_queue_init(&amp;free);<br>ngx_queue_init()的宏定义如下：</p>
<p>#define ngx_queue_init(q) \<br>(q)-&gt;prev = q; \<br> (q)-&gt;next = q;<br>可见初始的时候哨兵节点的 prev 和 next 都指向自己，因此其实是一个空链表。ngx_queue_empty()可以用来判断一个链表是否为空，其实现也很简单，就是：</p>
<p>#define ngx_queue_empty(h) \<br>(h == (h)-&gt;prev)<br>那么如何声明一个具有数据元素的链表节点呢？只要在相应的结构体中加上一个 ngx_queue_t 的成员就行了。比如ngx_http_upstream_keepalive_module中的ngx_http_upstream_keepalive_cache_t：</p>
<p>typedef struct {<br>ngx_http_upstream_keepalive_srv_conf_t <em>conf;<br>ngx_queue_t queue;<br>ngx_connection_t </em>connection;<br>socklen_t socklen;<br>u_char sockaddr[NGX_SOCKADDRLEN];<br>} ngx_http_upstream_keepalive_cache_t;<br>对于每一个这样的数据节点，可以通过ngx_queue_insert_head()来添加到链表中，第一个参数是哨兵节点，第二个参数是数据节点，比如：</p>
<p>ngx_http_upstream_keepalive_cache_t cache;<br>ngx_queue_insert_head(&amp;free, &amp;cache.queue);<br>相应的几个宏定义如下：</p>
<p>#define ngx_queue_insert_head(h, x) \<br>(x)-&gt;next = (h)-&gt;next; \<br>(x)-&gt;next-&gt;prev = x; \<br>(x)-&gt;prev = h; \<br>(h)-&gt;next = x</p>
<p>#define ngx_queue_insert_after ngx_queue_insert_head</p>
<p>#define ngx_queue_insert_tail(h, x) \<br>(x)-&gt;prev = (h)-&gt;prev; \<br>(x)-&gt;prev-&gt;next = x; \<br>(x)-&gt;next = h; \<br>(h)-&gt;prev = x<br>ngx_queue_insert_head()和ngx_queue_insert_after()都是往头部添加节点，ngx_queue_insert_tail()是往尾部添加节点。从代码可以看出哨兵节点的 prev 指向链表的尾数据节点，next 指向链表的头数据节点。另外ngx_queue_head()和ngx_queue_last()这两个宏分别可以得到头节点和尾节点。</p>
<p>那假如现在有一个ngx_queue_t *q 指向的是链表中的数据节点的queue成员，如何得到ngx_http_upstream_keepalive_cache_t的数据呢？ nginx提供了ngx_queue_data()宏来得到ngx_http_upstream_keepalive_cache_t的指针，例如：</p>
<p>ngx_http_upstream_keepalive_cache_t *cache = ngx_queue_data(q,<br>ngx_http_upstream_keepalive_cache_t,<br>queue);<br>也许您已经可以猜到ngx_queue_data是通过地址相减来得到的：</p>
<p>#define ngx_queue_data(q, type, link) \<br>(type <em>) ((u_char </em>) q - offsetof(type, link))<br>另外nginx也提供了ngx_queue_remove()宏来从链表中删除一个数据节点，以及ngx_queue_add()用来将一个链表添加到另一个链表。</p>
<p>第八章 负载均衡简单配置实战</p>
<p>准备三台虚拟机来做这个实验：</p>
<p>192.168.232.132 web服务器<br>192.168.232.133 web服务器<br>192.168.232.134 负载均衡服务器<br>预装nginx软件</p>
<p>导入外部软件库<br>rpm -Uvh <a href="http://dl.iuscommunity.org/pub/ius/stable/Redhat/6/i386/epel-release-6-5.noarch.rpm" target="_blank" rel="external">http://dl.iuscommunity.org/pub/ius/stable/Redhat/6/i386/epel-release-6-5.noarch.rpm</a><br>rpm -Uvh <a href="http://dl.iuscommunity.org/pub/ius/stable/Redhat/6/i386/ius-release-1.0-10.ius.el6.noarch.rpm" target="_blank" rel="external">http://dl.iuscommunity.org/pub/ius/stable/Redhat/6/i386/ius-release-1.0-10.ius.el6.noarch.rpm</a><br>rpm -Uvh <a href="http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm" target="_blank" rel="external">http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm</a><br>以下添加注释<br>mirrorlist=<a href="http://dmirr.iuscommunity.org/mirrorlist?repo=ius-el6&amp;arch=$basearch" target="_blank" rel="external">http://dmirr.iuscommunity.org/mirrorlist?repo=ius-el6&amp;arch=$basearch</a><br>以下删除注释</p>
<p>#baseurl=<a href="http://dl.iuscommunity.org/pub/ius/stable/Redhat/5/$basearch" target="_blank" rel="external">http://dl.iuscommunity.org/pub/ius/stable/Redhat/5/$basearch</a><br>yum安装nginx<br>yum install nginx<br>启动nginx<br>chkconfig nginx on<br>service nginx start<br>向web服务器中放入测试文件</p>
<p><html>    </html></p>
<p><head>    </head></p>
<p><title>Welcome to nginx!</title><br>    </p>
<p><body bgcolor="white" text="black">    </body></p>
<p><center><h1>Welcome to nginx! 192.168.232.132</h1></center><br><br><br>配置负载均衡服务器</p>
<p>vi /etc/nginx/nginx.conf<br>内容如下：<br>user  nginx;<br>worker_processes  1;  </p>
<p>error_log  /var/log/nginx/error.log warn;<br>pid        /var/run/nginx.pid;  </p>
<p>events {<br>    worker_connections  1024;<br>}  </p>
<p>http {<br>    include       /etc/nginx/mime.types;<br>    default_type  application/octet-stream;  </p>
<pre><code>log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;  
                  &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;  
                  &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;  

access_log  /var/log/nginx/access.log  main;  

sendfile        on;  
#tcp_nopush     on;  

keepalive_timeout  65;  

#gzip  on;  
upstream test.miaohr.com {  
server 192.168.232.132:80;  
server 192.168.232.133:80;  
}  


server {     
    listen       80;     
    server_name  test.miaohr.com;     
    charset utf-8;     
    location / {     
        root   html;     
        index  index.html index.htm;     
        proxy_pass        http://test.miaohr.com;     
        proxy_set_header  X-Real-IP  $remote_addr;     
        client_max_body_size  100m;  
    }     


    location ~ ^/(WEB-INF)/ {      
    deny all;      
    }      

    error_page   500 502 503 504  /50x.html;     
    location = /50x.html {     
        root   /var/www/html/;     
    }     
}     
</code></pre><p>}<br>下面浏览器打开:192.168.232.134，如果132、133交替显示则表明试验成功。</p>
<p>拓展：</p>
<p>轮询（默认）<br>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。<br>weight<br>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。<br>例如：<br>upstream bakend {<br>server 192.168.159.10 weight=10;<br>server 192.168.159.11 weight=10;<br>}<br>ip_hash<br>每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。<br>例如：<br>upstream resinserver{<br>ip_hash;<br>server 192.168.159.10:8080;<br>server 192.168.159.11:8080;<br>}<br>air（第三方）<br>按后端服务器的响应时间来分配请求，响应时间短的优先分配。<br>upstream resinserver{<br>server server1;<br>server server2;<br>fair;<br>}<br>url_hash（第三方）<br>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。<br>例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法<br>upstream resinserver{<br>server squid1:3128;<br>server squid2:3128;<br>hash $request_uri;<br>hash_method crc32;<br>}<br>tips:</p>
<p>upstream resinserver  </p>
<pre><code>    #error_page  404              /404.html;  

    # redirect server error pages to the static page /50x.html  
    #  
    error_page   500 502 503 504  /50x.html;  
    location = /50x.html {  
        root   html;  
    }  

    location = /baidu_verify_CXOKsFqzpJ.html {  
    root    html;  
}  

    location = /baidusilian.txt {  
    root html;  
}  

    location = /robots.txt {  
    root html;  
    }  

    # proxy the PHP scripts to Apache listening on 127.0.0.1:80  
    #  
    #location ~ \.php$ {  
    #    proxy_pass   http://127.0.0.1;  
    #}  

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000  
    #  
    #location ~ \.php$ {  
    #    root           html;  
    #    fastcgi_pass   127.0.0.1:9000;  
    #    fastcgi_index  index.php;  
    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;  
    #    include        fastcgi_params;  
    #}  

    # deny access to .htaccess files, if Apache&apos;s document root  
    # concurs with nginx&apos;s one  
    #  
    #location ~ /\.ht {  
    #    deny  all;  
    #}  

    #设定查看Nginx状态的地址 ，在安装时要加上--with-http_stub_status_module参数   
    location /NginxStatus {   
         stub_status on;   
         access_log on;   
         auth_basic &quot;NginxStatus&quot;;   
         auth_basic_user_file conf/htpasswd;     #设置访问密码，htpasswd -bc filename username password   
    }  
}  

# another virtual host using mix of IP-, name-, and port-based configuration  
#  
#server {  
#    listen       8000;  
#    listen       somename:8080;  
#    server_name  somename  alias  another.alias;  

#    location / {  
#        root   html;  
#        index  index.html index.htm;  
#    }  
#}  


# HTTPS server  
#  
#server {  
#    listen       443 ssl;  
#    server_name  localhost;  

#    ssl_certificate      cert.pem;  
#    ssl_certificate_key  cert.key;  

#    ssl_session_cache    shared:SSL:1m;  
#    ssl_session_timeout  5m;  

#    ssl_ciphers  HIGH:!aNULL:!MD5;  
#    ssl_prefer_server_ciphers  on;  

#    location / {  
#        root   html;  
#        index  index.html index.htm;  
#    }  
#}  



# 设置只允许通过域名访问站点     
server {  
listen 80 default_server;  
server_name _;  
return 403;  
</code></pre><p>   }  </p>
<p>}<br>附录</p>
<p>作者：JokerW<br>链接：<a href="http://www.jianshu.com/p/630e2e1ca57f" target="_blank" rel="external">http://www.jianshu.com/p/630e2e1ca57f</a><br>來源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;第一章-Nginx简介&quot;&gt;&lt;a href=&quot;#第一章-Nginx简介&quot; class=&quot;headerlink&quot; title=&quot;第一章 Nginx简介&quot;&gt;&lt;/a&gt;第一章 Nginx简介&lt;/h3&gt;&lt;h3 id=&quot;Nginx是什么&quot;&gt;&lt;a href=&quot;#Nginx是什么&quot;
    
    </summary>
    
      <category term="nginx" scheme="http://yoursite.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://yoursite.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2017/08/23/title/"/>
    <id>http://yoursite.com/2017/08/23/title/</id>
    <published>2017-08-23T13:27:00.000Z</published>
    <updated>2017-08-23T14:21:17.048Z</updated>
    
    <content type="html"><![CDATA[<h1 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world!"></a>hello world!</h1><div class="tip">今天是周末!</div>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;hello-world&quot;&gt;&lt;a href=&quot;#hello-world&quot; class=&quot;headerlink&quot; title=&quot;hello world!&quot;&gt;&lt;/a&gt;hello world!&lt;/h1&gt;&lt;div class=&quot;tip&quot;&gt;今天是周末!&lt;/div&gt;
    
    </summary>
    
      <category term="spring" scheme="http://yoursite.com/categories/spring/"/>
    
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
  </entry>
  
</feed>
